<!DOCTYPE html>
<html lang="en">

  <head>
    <title>RSS Feed Reader</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="RSS Feed Reader" href="feed.atom" />
    <link href="index.css?v1.14.4" rel="stylesheet" />
    <!-- %before-head-end.html% -->
  </head>

  <body>
    <!-- %after-body-begin.html% -->
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-19 datetime="2025-06-19T19:47:41.000Z">2025-06-19</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-19 datetime="2025-06-19T19:47:41.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="532d18b968f9fc9b62e3a78ab5c765ff00f8c111"
                        open
                      >
                        <summary class="article-expander__title">Build a scalable AI video generator using Amazon SageMaker AI and CogVideoX</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-scalable-ai-video-generator-using-amazon-sagemaker-ai-and-cogvideox/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/10/ML-17715-video-3-1749587457635.gif" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In recent years, the rapid advancement of artificial intelligence and machine learning (AI/ML) technologies has revolutionized various aspects of digital content creation. One particularly exciting development is the emergence of video generation capabilities, which offer unprecedented opportunities for companies across diverse industries. This technology allows for the creation of short video clips that can be […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="fd0ce0a6b2728499b9ce1303b9a088ddfb5375da"
                        open
                      >
                        <summary class="article-expander__title">Building trust in AI: The AWS approach to the EU AI Act</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/building-trust-in-ai-the-aws-approach-to-the-eu-ai-act/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/19/trust.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>The EU AI Act establishes comprehensive regulations for AI development and deployment within the EU. AWS is committed to building trust in AI through various initiatives including being among the first signatories of the EU&#x27;s AI Pact, providing AI Service Cards and guardrails, and offering educational resources while helping customers understand their responsibilities under the new regulatory framework.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;91
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5fdb3206727328d4ef3f0c9af446321f92a64175"
                        open
                      >
                        <summary class="article-expander__title">Update on the AWS DeepRacer Student Portal</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/update-on-the-aws-deepracer-student-portal/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/13/featured-images-ML-19120-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Starting July 14, 2025, the AWS DeepRacer Student Portal will enter a maintenance phase where new registrations will be disabled. Until September 15, 2025, existing users will retain full access to their content and training materials, with updates limited to critical security fixes, after which the portal will no longer be available.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;88
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="48e446c3aebb4eff0674b8ccb2856acfa787144e"
                        open
                      >
                        <summary class="article-expander__title">Accelerate foundation model training and inference with Amazon SageMaker HyperPod and Amazon SageMaker Studio</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accelerate-foundation-model-training-and-inference-with-amazon-sagemaker-hyperpod-and-amazon-sagemaker-studio/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/11/ML-18718-archdiag-1122x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we discuss how SageMaker HyperPod and SageMaker Studio can improve and speed up the development experience of data scientists by using IDEs and tooling of SageMaker Studio and the scalability and resiliency of SageMaker HyperPod with Amazon EKS. The solution simplifies the setup for the system administrator of the centralized system by using the governance and security capabilities offered by the AWS services.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;100
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-18 datetime="2025-06-18T16:13:36.000Z">2025-06-18</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-18 datetime="2025-06-18T16:13:36.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="e676fa172b3b1119f585f0a3069b6a92037da4a1"
                        open
                      >
                        <summary class="article-expander__title">Meeting summarization and action item extraction with Amazon Nova</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/meeting-summarization-and-action-item-extraction-with-amazon-nova/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/11/cisco-webex-summarization-1.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we present a benchmark of different understanding models from the Amazon Nova family available on Amazon Bedrock, to provide insights on how you can choose the best model for a meeting summarization task.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="0378d56ae5b9e3012e332cb21e93a2275ce73869"
                        open
                      >
                        <summary class="article-expander__title">Building a custom text-to-SQL agent using Amazon Bedrock and Converse API</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/building-a-custom-text-to-sql-agent-using-amazon-bedrock-and-converse-api/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/02/ML-16627-image-1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Developing robust text-to-SQL capabilities is a critical challenge in the field of natural language processing (NLP) and database management. The complexity of NLP and database management increases in this field, particularly while dealing with complex queries and database structures. In this post, we introduce a straightforward but powerful solution with accompanying code to text-to-SQL using a custom agent implementation along with Amazon Bedrock and Converse API.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6433d5c86a881d13beae153926530bab132bd3a0"
                        open
                      >
                        <summary class="article-expander__title">Accelerate threat modeling with generative AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accelerate-threat-modeling-with-generative-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/18/ML-18677-shift-left-1260x482.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how generative AI can revolutionize threat modeling practices by automating vulnerability identification, generating comprehensive attack scenarios, and providing contextual mitigation strategies.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-17 datetime="2025-06-17T15:02:07.000Z">2025-06-17</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-17 datetime="2025-06-17T15:02:07.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="a8455536d076e604df78456037ecadc1bf405da1"
                        open
                      >
                        <summary class="article-expander__title">How Anomalo solves unstructured data quality issues to deliver trusted assets for AI with AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-anomalo-solves-unstructured-data-quality-issues-to-deliver-trusted-assets-for-ai-with-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/11/Anomalo-AWS-ML-Blog-Figure-1-1260x547.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how you can use Anomalo with Amazon Web Services (AWS) AI and machine learning (AI/ML) to profile, validate, and cleanse unstructured data collections to transform your data lake into a trusted source for production ready AI initiatives.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="284fa695e4216c58599cb8b346e2d5fca604b716"
                        open
                      >
                        <summary class="article-expander__title">An innovative financial services leader finds the right AI solution: Robinhood and Amazon Nova</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/an-innovative-financial-services-leader-finds-the-right-ai-solution-robinhood-and-amazon-nova/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/17/robinhood-nova.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we share how Robinhood delivers democratized finance and real-time market insights using generative AI and Amazon Nova.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;91
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="9334b67e27da30f06b3b3467c068b42da1b39daf"
                        open
                      >
                        <summary class="article-expander__title">Build conversational interfaces for structured data using Amazon Bedrock Knowledge Bases</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-conversational-interfaces-for-structured-data-using-amazon-bedrock-knowledge-bases/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/17/build-conversational-interfaces.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post provides instructions to configure a structured data retrieval solution, with practical code examples and templates. It covers implementation samples and additional considerations, empowering you to quickly build and scale your conversational data interfaces.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-16 datetime="2025-06-16T17:22:05.000Z">2025-06-16</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-16 datetime="2025-06-16T17:22:05.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="530dc9578cef6d53be4046ad41465c6c9d565241"
                        open
                      >
                        <summary class="article-expander__title">How Apollo Tyres is unlocking machine insights using agentic AI-powered Manufacturing Reasoner</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-apollo-tyres-is-unlocking-machine-insights-using-agentic-ai-powered-manufacturing-reasoner/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/05/ml17028-image-2-1185x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we share how Apollo Tyres used generative AI with Amazon Bedrock to harness the insights from their machine data in a natural language interaction mode to gain a comprehensive view of its manufacturing processes, enabling data-driven decision-making and optimizing operational efficiency.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5b6f3853c156f0581388515680de9a6d5ddef8a2"
                        open
                      >
                        <summary class="article-expander__title">Extend your Amazon Q Business with PagerDuty Advance data accessor</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/extend-your-amazon-q-business-with-pagerduty-advance-data-accessor/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/28/blog-pdadvance-asset1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how organizations can enhance their incident management capabilities by integrating PagerDuty Advance, an innovative set of agentic and generative AI capabilities that automate response workflows and provide real-time insights into operational health, with Amazon Q Business. We show how to configure PagerDuty Advance as a data accessor for Amazon Q indexes, so you can search and access enterprise knowledge across multiple systems during incident response.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="ff1f88e8aea1604a62f8523ab1dfa61b2df9906a"
                        open
                      >
                        <summary class="article-expander__title">Innovate business logic by implementing return of control in Amazon Bedrock Agents</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/innovate-business-logic-by-implementing-return-of-control-in-amazon-bedrock-agents/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/24/arch.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In the context of distributed systems and microservices architecture, orchestrating communication between diverse components presents significant challenges. However, with the launch of Amazon Bedrock Agents, the landscape is evolving, offering a simplified approach to agent creation and seamless integration of the return of control capability. In this post, we explore how Amazon Bedrock Agents revolutionizes agent creation and demonstrates the efficacy of the return of control capability in orchestrating complex interactions between multiple systems.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1651"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #481</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-481/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com A message from our sponsor, PagerDuty: Need Slack-native E2E incident management? PagerDuty delivers! Automatic incident workflows that set up Slack channels? ✅ Incident roles and built-in commands? ✅ AI-powered chat that provides real-time customer impact? ✅ Now available on ALL paid PagerDuty plans. https://fnf.dev/4dZ5V36 Google Cloud Platform Incident, June 12, 2025 On […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-13 datetime="2025-06-13T17:17:22.000Z">2025-06-13</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-13 datetime="2025-06-13T17:17:22.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="cb5545a1b55d7445cbf71e420df3c3a1372acad5"
                        open
                      >
                        <summary class="article-expander__title">Deploy Qwen models with Amazon Bedrock Custom Model Import</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/deploy-qwen-models-with-amazon-bedrock-custom-model-import/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/13/ML-18505-image-10-840x630.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>You can now import custom weights for Qwen2, Qwen2_VL, and Qwen2_5_VL architectures, including models like Qwen 2, 2.5 Coder, Qwen 2.5 VL, and QwQ 32B. In this post, we cover how to deploy Qwen 2.5 models with Amazon Bedrock Custom Model Import, making them accessible to organizations looking to use state-of-the-art AI capabilities within the AWS infrastructure at an effective cost.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="7025d99e2b4da209dae1b73efecb58c2b9052605"
                        open
                      >
                        <summary class="article-expander__title">Build generative AI solutions with Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-generative-ai-solutions-with-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/13/build-genai-bedrock.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show you how to build generative AI applications on Amazon Web Services (AWS) using the capabilities of Amazon Bedrock, highlighting how Amazon Bedrock can be used at each step of your generative AI journey. This guide is valuable for both experienced AI engineers and newcomers to the generative AI space, helping you use Amazon Bedrock to its fullest potential.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;17
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="15de2e8168d76b5ec64a123c704e2f042ca76e21"
                        open
                      >
                        <summary class="article-expander__title">How Netsertive built a scalable AI assistant to extract meaningful insights from real-time data using Amazon Bedrock and Amazon Nova</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-netsertive-built-a-scalable-ai-assistant-to-extract-meaningful-insights-from-real-time-data-using-amazon-bedrock-and-amazon-nova/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/05/ml-18574-Arch-1096x630.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show how Netsertive introduced a generative AI-powered assistant into MLX, using Amazon Bedrock and Amazon Nova, to bring their next generation of the platform to life.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="54416643422ef294dd1450aed6d2cb2e547588c3"
                        open
                      >
                        <summary class="article-expander__title">Make videos accessible with automated audio descriptions using Amazon Nova</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/make-videos-accessible-with-automated-audio-descriptions-using-amazon-nova/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/02/image-1-1179x630.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how you can use services like Amazon Nova, Amazon Rekognition, and Amazon Polly to automate the creation of accessible audio descriptions for video content. This approach can significantly reduce the time and cost required to make videos accessible for visually impaired audiences.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="35c33f201c2eaf00cbd1e8eaafecd857c1c31b6a"
                        open
                      >
                        <summary class="article-expander__title">Training Llama 3.3 Swallow: A Japanese sovereign LLM on Amazon SageMaker HyperPod</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/training-llama-3-3-swallow-a-japanese-sovereign-llm-on-amazon-sagemaker-hyperpod/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/28/HyperPod-deepdive-2025.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>The Institute of Science Tokyo has successfully trained Llama 3.3 Swallow, a 70-billion-parameter large language model (LLM) with enhanced Japanese capabilities, using Amazon SageMaker HyperPod. The model demonstrates superior performance in Japanese language tasks, outperforming GPT-4o-mini and other leading models. This technical report details the training infrastructure, optimizations, and best practices developed during the project.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-12 datetime="2025-06-12T17:48:44.000Z">2025-06-12</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-12 datetime="2025-06-12T17:48:44.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="7db70e68de0fc77d098fb1e60a130172be8697ca"
                        open
                      >
                        <summary class="article-expander__title">Accelerating Articul8’s domain-specific model development with Amazon SageMaker HyperPod</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accelerating-articul8s-domain-specific-model-development-with-amazon-sagemaker-hyperpod/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/26/ml-17638-arch-1-1135x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Learn how Articul8 is redefining enterprise generative AI with domain-specific models that outperform general-purpose LLMs in real-world applications. In our latest blog post, we dive into how Amazon SageMaker HyperPod accelerated the development of Articul8’s industry-leading semiconductor model—achieving 2X higher accuracy that top open source models while slashing deployment time by 4X.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="2eab9613583f33b9a7d1a59682ca32e290ca074d"
                        open
                      >
                        <summary class="article-expander__title">How VideoAmp uses Amazon Bedrock to power their media analytics interface</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-videoamp-uses-amazon-bedrock-to-power-their-media-analytics-interface/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/14/VideoAmp-Architecture-copy.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we illustrate how VideoAmp, a media measurement company, worked with the AWS Generative AI Innovation Center (GenAIIC) team to develop a prototype of the VideoAmp Natural Language (NL) Analytics Chatbot to uncover meaningful insights at scale within media analytics data using Amazon Bedrock.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-11 datetime="2025-06-11T21:07:06.000Z">2025-06-11</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-11 datetime="2025-06-11T21:07:06.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6353"
                        open
                      >
                        <summary class="article-expander__title">Failures of Imagination (again)</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/06/11/failures-of-imagination-again/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://s0.wp.com/i/blank.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>TL;DR I’m once again hearing “who could have imagined?” for things that are very easy to imagine. If you actually stop for a moment and do some imagination, and maybe prep your mind with some science fiction, and perhaps also listen to early career voices. Again? I’ve written on this topic before. Though last time […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="d241f085e1fc7119e970a07ea8d64497034dcee4"
                        open
                      >
                        <summary class="article-expander__title">Adobe enhances developer productivity using Amazon Bedrock Knowledge Bases</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/adobe-enhances-developer-productivity-using-amazon-bedrock-knowledge-bases/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/02/ml-17793-image-1-1018x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Adobe partnered with the AWS Generative AI Innovation Center, using Amazon Bedrock Knowledge Bases and the Vector Engine for Amazon OpenSearch Serverless. This solution dramatically improved their developer support system, resulting in a 20% increase in retrieval accuracy. In this post, we discuss the details of this solution and how Adobe enhances their developer productivity.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="57f64f0595efe9b823d2f02481ee1d1b2b883b0c"
                        open
                      >
                        <summary class="article-expander__title">Amazon Nova Lite enables Bito to offer a free tier option for its AI-powered code reviews</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/amazon-nova-lite-enables-bito-to-offer-a-free-tier-option-for-its-ai-powered-code-reviews/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/11/nova-lite-bito.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Bito is an innovative startup that creates AI agents for a broad range of software developers. In this post, we share how Bito is able to offer a free tier option for its AI-powered code reviews using Amazon Nova.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="b5389e810ef08b3bc87e1eef6d65e8e06aafe1f8"
                        open
                      >
                        <summary class="article-expander__title">How Gardenia Technologies helps customers create ESG disclosure reports 75% faster using agentic generative AI on Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-gardenia-technologies-helps-customers-create-esg-disclosure-reports-75-faster-using-agentic-generative-ai-on-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/02/ML-18101-architecture-833x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Gardenia Technologies, a data analytics company, partnered with the AWS Prototyping and Cloud Engineering (PACE) team to develop Report GenAI, a fully automated ESG reporting solution powered by the latest generative AI models on Amazon Bedrock. This post dives deep into the technology behind an agentic search solution using tooling with Retrieval Augmented Generation (RAG) and text-to-SQL capabilities to help customers reduce ESG reporting time by up to 75%. We demonstrate how AWS serverless technology, combined with agents in Amazon Bedrock, are used to build scalable and highly flexible agent-based document assistant applications.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="2d1e0b43624b483236e6e151a1c37c27794b41f7"
                        open
                      >
                        <summary class="article-expander__title">NVIDIA Nemotron Super 49B and Nano 8B reasoning models now available in Amazon Bedrock Marketplace and Amazon SageMaker JumpStart</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/nvidia-nemotron-super-49b-and-nano-8b-reasoning-models-now-available-in-amazon-bedrock-marketplace-and-amazon-sagemaker-jumpstart/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/11/featured-images-ML-19048-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>The Llama 3.3 Nemotron Super 49B V1 and Llama 3.1 Nemotron Nano 8B V1 are now available in Amazon Bedrock Marketplace and Amazon SageMaker JumpStart. With this launch, you can now deploy NVIDIA’s newest reasoning models to build, experiment, and responsibly scale your generative AI ideas on AWS.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-10 datetime="2025-06-10T16:19:09.000Z">2025-06-10</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-10 datetime="2025-06-10T16:19:09.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="7aa8f1971489eeaa2440e0577f91271167b77972"
                        open
                      >
                        <summary class="article-expander__title">Automate customer support with Amazon Bedrock, LangGraph, and Mistral models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/automate-customer-support-with-amazon-bedrock-langgraph-and-mistral-models/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/02/ML-18686-solution-arch-2-1260x523.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to use Amazon Bedrock and LangGraph to build a personalized customer support experience for an ecommerce retailer. By integrating the Mistral Large 2 and Pixtral Large models, we guide you through automating key customer support workflows such as ticket categorization, order details extraction, damage assessment, and generating contextual responses.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="736dc7391f88397fb4c116138cdadb6cda3c4c00"
                        open
                      >
                        <summary class="article-expander__title">Build responsible AI applications with Amazon Bedrock Guardrails</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-responsible-ai-applications-with-amazon-bedrock-guardrails/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/ML17857-arch-diag-1260x534.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how Amazon Bedrock Guardrails helps block harmful and undesirable multimodal content. Using a healthcare insurance call center scenario, we walk through the process of configuring and testing various guardrails.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="fdcdf16b55cfb6df4b93f170ad0994b0c12473b9"
                        open
                      >
                        <summary class="article-expander__title">Effective cost optimization strategies for Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/effective-cost-optimization-strategies-for-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/31/ML-18577-approach-decision-maker-1260x566.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>With the increasing adoption of Amazon Bedrock, optimizing costs is a must to help keep the expenses associated with deploying and running generative AI applications manageable and aligned with your organization’s budget. In this post, you’ll learn about strategic cost optimization techniques while using Amazon Bedrock.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="8af0789a0c380421a5317fd8ea95a64ec86a7465"
                        open
                      >
                        <summary class="article-expander__title">How E.ON saves £10 million annually with AI diagnostics for smart meters powered by Amazon Textract</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-e-on-saves-10-million-annually-with-ai-diagnostics-for-smart-meters-powered-by-amazon-textract/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/30/ML-18474-image-4-1232x630.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>E.ON’s story highlights how a creative application of Amazon Textract, combined with custom image analysis and pulse counting, can solve a real-world challenge at scale. By diagnosing smart meter errors through brief smartphone videos, E.ON aims to lower costs, improve customer satisfaction, and enhance overall energy service reliability. In this post, we dive into how this solution works and the impact it’s making.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-09 datetime="2025-06-09T15:50:24.000Z">2025-06-09</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-09 datetime="2025-06-09T15:50:24.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="e097c4af840d23d119a36dedaf3df20f8118cf0f"
                        open
                      >
                        <summary class="article-expander__title">Building intelligent AI voice agents with Pipecat and Amazon Bedrock – Part 1</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/building-intelligent-ai-voice-agents-with-pipecat-and-amazon-bedrock-part-1/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/10/Cover-Voice-AI-agents-1120x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this series of posts, you will learn how to build intelligent AI voice agents using Pipecat, an open-source framework for voice and multimodal conversational AI agents, with foundation models on Amazon Bedrock. It includes high-level reference architectures, best practices and code samples to guide your implementation.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5ba9900fe962810f04b60366ba90d3a8a4753c61"
                        open
                      >
                        <summary class="article-expander__title">Stream multi-channel audio to Amazon Transcribe using the Web Audio API</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/stream-multi-channel-audio-to-amazon-transcribe-using-the-web-audio-api/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/01/Picture1-17.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore the implementation details of a web application that uses the browser’s Web Audio API and Amazon Transcribe streaming to enable real-time dual-channel transcription. By using the combination of AudioContext, ChannelMergerNode, and AudioWorklet, we were able to seamlessly process and encode the audio data from two microphones before sending it to Amazon Transcribe for transcription.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="db12f9abc38a429c3b44d3b3b6e2c6d4f43aa4aa"
                        open
                      >
                        <summary class="article-expander__title">How Kepler democratized AI access and enhanced client services with Amazon Q Business</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-kepler-democratized-ai-access-and-enhanced-client-services-with-amazon-q-business/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/03/ML-18968-image-1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>At Kepler, a global full-service digital marketing agency serving Fortune 500 brands, we understand the delicate balance between creative marketing strategies and data-driven precision. In this post, we share how implementing Amazon Q Business transformed our operations by democratizing AI access across our organization while maintaining stringent security standards, resulting in an average savings of 2.7 hours per week per employee in manual work and improved client service delivery.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6339"
                        open
                      >
                        <summary class="article-expander__title">Dart binaries in Python packages</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/06/09/dart-binaries-in-python-packages/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://s0.wp.com/i/blank.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>TL;DR PyPI provides a neat way of distributing binaries from other languages, and Python venvs make it easy to run different versions side by side. This post takes a look at how to do that with Dart, and the next steps necessary to do a proper job of it. Background A few days ago I […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1649"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #480</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-480/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com A message from our sponsor, PagerDuty: 🔍 Notable PagerDuty shift: Full incident management now spans all paid tiers. The upgraded Slack-first and Teams-first experience means fewer tools to juggle during incidents. Only leveraging PagerDuty for basic alerting? Time to check out what’s newly available in your plan! https://fnf.dev/4dZ5V36 You can’t prevent your […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-06 datetime="2025-06-06T17:34:31.000Z">2025-06-06</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-06 datetime="2025-06-06T17:34:31.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5a6a5e152dd1e382b4fd03a685f16a6d3400e297"
                        open
                      >
                        <summary class="article-expander__title">Build a serverless audio summarization solution with Amazon Bedrock and Whisper</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-serverless-audio-summarization-solution-with-amazon-bedrock-and-whisper/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/19/Picture2-4-crop.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to use the Open AI Whisper foundation model (FM) Whisper Large V3 Turbo, available in Amazon Bedrock Marketplace, which offers access to over 140 models through a dedicated offering, to produce near real-time transcription. These transcriptions are then processed by Amazon Bedrock for summarization and redaction of sensitive information.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="ecc7ca1bb5896b73806a97065e5af80edbfea514"
                        open
                      >
                        <summary class="article-expander__title">Implement semantic video search using open source large vision models on Amazon SageMaker and Amazon OpenSearch Serverless</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/implement-semantic-video-search-using-open-source-large-vision-models-on-amazon-sagemaker-and-amazon-opensearch-serverless/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/07/fig1-1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to use large vision models (LVMs) for semantic video search using natural language and image queries. We introduce some use case-specific methods, such as temporal frame smoothing and clustering, to enhance the video search performance. Furthermore, we demonstrate the end-to-end functionality of this approach by using both asynchronous and real-time hosting options on Amazon SageMaker AI to perform video, image, and text processing using publicly available LVMs on the Hugging Face Model Hub. Finally, we use Amazon OpenSearch Serverless with its vector engine for low-latency semantic video search.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="e917b802ba8b25de8e0d3191f459fab8b48c3e35"
                        open
                      >
                        <summary class="article-expander__title">Multi-account support for Amazon SageMaker HyperPod task governance</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/multi-account-support-for-amazon-sagemaker-hyperpod-task-governance/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/28/access-points-jpmc.drawio-2-701x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we discuss how an enterprise with multiple accounts can access a shared Amazon SageMaker HyperPod cluster for running their heterogenous workloads. We use SageMaker HyperPod task governance to enable this feature.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6074fa33042c619e87fded8a1e64a99e6ec76126"
                        open
                      >
                        <summary class="article-expander__title">Build a Text-to-SQL solution for data consistency in generative AI using Amazon Nova</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-text-to-sql-solution-for-data-consistency-in-generative-ai-using-amazon-nova/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/23/ML-17543-arch-diag.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post evaluates the key options for querying data using generative AI, discusses their strengths and limitations, and demonstrates why Text-to-SQL is the best choice for deterministic, schema-specific tasks. We show how to effectively use Text-to-SQL using Amazon Nova, a foundation model (FM) available in Amazon Bedrock, to derive precise and reliable answers from your data.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6328"
                        open
                      >
                        <summary class="article-expander__title">Dealing with Policy Debt</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/06/06/dealing-with-policy-debt/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://s0.wp.com/i/blank.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>TL;DR Start writing down why decisions are made. Future you may thank you. Future other person who’s wondering what you were thinking may also thank you. Then keep a dependency graph of the things impacted by the decision. It will help unravel what gets woven around it. Background I was at an excellent AFCEA event […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-05 datetime="2025-06-05T16:40:32.000Z">2025-06-05</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-05 datetime="2025-06-05T16:40:32.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="26d9ee9cb82638d9cf710c0c2633411cd20d810e"
                        open
                      >
                        <summary class="article-expander__title">Modernize and migrate on-premises fraud detection machine learning workflows to Amazon SageMaker</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/modernize-and-migrate-on-premises-fraud-detection-machine-learning-workflows-to-amazon-sagemaker/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/22/ML-17395-1-Legacy-architecture-1-796x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Radial is the largest 3PL fulfillment provider, also offering integrated payment, fraud detection, and omnichannel solutions to mid-market and enterprise brands. In this post, we share how Radial optimized the cost and performance of their fraud detection machine learning (ML) applications by modernizing their ML workflow using Amazon SageMaker.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="94e43b5f050984d07a671df4b0b5f596953d31ad"
                        open
                      >
                        <summary class="article-expander__title">Contextual retrieval in Anthropic using Amazon Bedrock Knowledge Bases</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/contextual-retrieval-in-anthropic-using-amazon-bedrock-knowledge-bases/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/05/contextual-retrieval.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Contextual retrieval enhances traditional RAG by adding chunk-specific explanatory context to each chunk before generating embeddings. This approach enriches the vector representation with relevant contextual information, enabling more accurate retrieval of semantically related content when responding to user queries. In this post, we demonstrate how to use contextual retrieval with Anthropic and Amazon Bedrock Knowledge Bases.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="f1c484e234ef857fc38050d28db3464ea042d620"
                        open
                      >
                        <summary class="article-expander__title">Run small language models cost-efficiently with AWS Graviton and Amazon SageMaker AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/run-small-language-models-cost-efficiently-with-aws-graviton-and-amazon-sagemaker-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/04/23/ML-18152-torch-diag.png-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to deploy a small language model on SageMaker AI by extending our pre-built containers to be compatible with AWS Graviton instances. We first provide an overview of the solution, and then provide detailed implementation steps to help you get started. You can find the example notebook in the GitHub repo.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-04 datetime="2025-06-04T21:20:47.000Z">2025-06-04</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-04 datetime="2025-06-04T21:20:47.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="9e02f996c5e3c80f14860bee9c7951901afe8e1e"
                        open
                      >
                        <summary class="article-expander__title">Impel enhances automotive dealership customer experience with fine-tuned LLMs on Amazon SageMaker</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/impel-enhances-automotive-dealership-customer-experience-with-fine-tuned-llms-on-amazon-sagemaker/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/27/ml-18410-arch-diag.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we share how Impel enhances the automotive dealership customer experience with fine-tuned LLMs on SageMaker.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="259f623956d3dd5819ce7d6bd0a6b9fc6ffa7876"
                        open
                      >
                        <summary class="article-expander__title">How climate tech startups are building foundation models with Amazon SageMaker HyperPod</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-climate-tech-startups-are-building-foundation-models-with-amazon-sagemaker-hyperpod/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/27/AGIClimate-image-1-1260x607.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show how climate tech startups are developing foundation models (FMs) that use extensive environmental datasets to tackle issues such as carbon capture, carbon-negative fuels, new materials design for microplastics destruction, and ecosystem preservation. These specialized models require advanced computational capabilities to process and analyze vast amounts of data effectively.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="90d51716ebb0bf0a6e473917ac8f73f19d948ed5"
                        open
                      >
                        <summary class="article-expander__title">Supercharge your development with Claude Code and Amazon Bedrock prompt caching</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/supercharge-your-development-with-claude-code-and-amazon-bedrock-prompt-caching/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/04/supercharge-claude.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we&#x27;ll explore how to combine Amazon Bedrock prompt caching with Claude Code—a coding agent released by Anthropic that is now generally available. This powerful combination transforms your development workflow by delivering lightning-fast responses from reducing inference response latency, as well as lowering input token costs.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-03 datetime="2025-06-03T16:53:40.000Z">2025-06-03</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-03 datetime="2025-06-03T16:53:40.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="13977db91c0667df2c60f5413703e78f125f9415"
                        open
                      >
                        <summary class="article-expander__title">Unlocking the power of Model Context Protocol (MCP) on AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/unlocking-the-power-of-model-context-protocol-mcp-on-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/23/ML-18605-bedrock-kb-architecture-884x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>We’ve witnessed remarkable advances in model capabilities as generative AI companies have invested in developing their offerings. Language models such as Anthropic’s Claude Opus 4 &amp; Sonnet 4, Amazon Nova, and Amazon Bedrock can reason, write, and generate responses with increasing sophistication. But even as these models grow more powerful, they can only work with […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;16
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="17c1ad8a3aa1ddac84328d052610f759cc45c367"
                        open
                      >
                        <summary class="article-expander__title">Build a scalable AI assistant to help refugees using AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-scalable-ai-assistant-to-help-refugees-using-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/15/photo_2025-05-14_14-28-29-AG-250515-1-1091x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>The Danish humanitarian organization Bevar Ukraine has developed a comprehensive virtual generative AI-powered assistant called Victor, aimed at addressing the pressing needs of Ukrainian refugees integrating into Danish society. This post details our technical implementation using AWS services to create a scalable, multilingual AI assistant system that provides automated assistance while maintaining data security and GDPR compliance.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6c5a159320be3c2e07fe7b729cc907f5a0aa84d4"
                        open
                      >
                        <summary class="article-expander__title">Enhanced diagnostics flow with LLM and Amazon Bedrock agent integration</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/enhanced-diagnostics-flow-with-llm-and-amazon-bedrock-agent-integration/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/20/Noodoe-GenAI-Data-Flow.drawio-870x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how Noodoe uses AI and Amazon Bedrock to optimize EV charging operations. By integrating LLMs, Noodoe enhances station diagnostics, enables dynamic pricing, and delivers multilingual support. These innovations reduce downtime, maximize efficiency, and improve sustainability. Read on to discover how AI is transforming EV charging management.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6317"
                        open
                      >
                        <summary class="article-expander__title">Using a Python venv to run different versions of CMake</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/06/03/using-a-python-venv-to-run-different-versions-of-cmake/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://s0.wp.com/i/blank.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Sometimes I need an older or newer version of CMake to the one installed by the system package manager on whatever I’m using, and I’ve found using a Python venv provides an easy way to do that. It’s all facilitated by the fact that CMake is a PyPI package [1]. For example, my Kubuntu desktop […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-02 datetime="2025-06-02T17:39:51.000Z">2025-06-02</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-02 datetime="2025-06-02T17:39:51.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="bbda6d388effd5a44bca2d930f35ee4d1f137b85"
                        open
                      >
                        <summary class="article-expander__title">Build GraphRAG applications using Amazon Bedrock Knowledge Bases</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-graphrag-applications-using-amazon-bedrock-knowledge-bases/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/19/ML-18340_002_architecture.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how to use Graph-based Retrieval-Augmented Generation (GraphRAG) in Amazon Bedrock Knowledge Bases to build intelligent applications. Unlike traditional vector search, which retrieves documents based on similarity scores, knowledge graphs encode relationships between entities, allowing large language models (LLMs) to retrieve information with context-aware reasoning.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="ddce93902a4813aa526a5a42e972c4eebe188fa0"
                        open
                      >
                        <summary class="article-expander__title">Streamline personalization development: How automated ML workflows accelerate Amazon Personalize implementation</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/streamline-personalization-development-how-automated-ml-workflows-accelerate-amazon-personalize-implementation/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/03/ML-17195-Picture1-1260x587.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This blog post presents an MLOps solution that uses AWS Cloud Development Kit (AWS CDK) and services like AWS Step Functions, Amazon EventBridge and Amazon Personalize to automate provisioning resources for data preparation, model training, deployment, and monitoring for Amazon Personalize.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="dc55c0b49c875a811a3e114c791325bab95ee403"
                        open
                      >
                        <summary class="article-expander__title">Fast-track SOP processing using Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/fast-track-sop-processing-using-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/16/ML-17198-arch-diag-Image-003-1152x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>When a regulatory body like the US Food and Drug Administration (FDA) introduces changes to regulations, organizations are required to evaluate the changes against their internal SOPs. When necessary, they must update their SOPs to align with the regulation changes and maintain compliance. In this post, we show different approaches using Amazon Bedrock to identify relationships between regulation changes and SOPs.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;18
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6282"
                        open
                      >
                        <summary class="article-expander__title">May 2025</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/06/02/may-2025/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/05/pups_202505.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Pupdate The fair weather has (mostly) continued, which allowed for some nice long walks. Milo turned four at the start of the month :) Brussels The end of the month brought the half term holiday, and Mrs S wanted to spend the first weekend away somewhere. Brussels quickly made the top of the list after […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://blog.thestateofme.com/?p&#x3D;6282"
                        open
                      >
                        <summary class="article-expander__title">May 2025</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://blog.thestateofme.com/2025/06/02/may-2025/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/05/pups_202505.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Pupdate The fair weather has (mostly) continued, which allowed for some nice long walks. Milo turned four at the start of the month :) Brussels The end of the month brought the half term holiday, and Mrs S wanted to spend the first weekend away somewhere. Brussels quickly made the top of the list after […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1644"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #479</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-479/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com Automatic rollbacks are a last resort Rollbacks don’t always return you to a previous system state. They can return you to a state you’ve never tested or operated before.   Steve Fenton — Octopus Deploy Burn rate is a better error rate This article explains the math of burn rate alerting and gives […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-30 datetime="2025-05-30T17:27:16.000Z">2025-05-30</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-30 datetime="2025-05-30T17:27:16.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="d7f85bb395e5d94da0c05bbf126af35c78256cb2"
                        open
                      >
                        <summary class="article-expander__title">Deploy Amazon SageMaker Projects with Terraform Cloud</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/deploy-amazon-sagemaker-projects-with-terraform-cloud/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/30/deploy-sagemaker-projects-terraform.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post you define, deploy, and provision a SageMaker Project custom template purely in Terraform. With no dependencies on other IaC tools, you can now enable SageMaker Projects strictly within your Terraform Enterprise infrastructure.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="18d316f7d52dafde0260f4c03c9632fd3035c21e"
                        open
                      >
                        <summary class="article-expander__title">How ZURU improved the accuracy of floor plan generation by 109% using Amazon Bedrock and Amazon SageMaker</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-zuru-improved-the-accuracy-of-floor-plan-generation-by-109-using-amazon-bedrock-and-amazon-sagemaker/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/14/PE-workflow-highres-1260x600.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>ZURU collaborated with AWS Generative AI Innovation Center and AWS Professional Services to implement a more accurate text-to-floor plan generator using generative AI. In this post, we show you why a solution using a large language model (LLM) was chosen. We explore how model selection, prompt engineering, and fine-tuning can be used to improve results.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="b462012de270e591499ba1c159ea3e9bfda36da6"
                        open
                      >
                        <summary class="article-expander__title">Going beyond AI assistants: Examples from Amazon.com reinventing industries with generative AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/going-beyond-ai-assistants-examples-from-amazon-com-reinventing-industries-with-generative-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/16/Picture8-blog17678-1-1135x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Non-conversational applications offer unique advantages such as higher latency tolerance, batch processing, and caching, but their autonomous nature requires stronger guardrails and exhaustive quality assurance compared to conversational applications, which benefit from real-time user feedback and supervision. This post examines four diverse Amazon.com examples of such generative AI applications.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="4b216781c496ceff2fc13b51dfa10b08ff663497"
                        open
                      >
                        <summary class="article-expander__title">Architect a mature generative AI foundation on AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/architect-a-mature-generative-ai-foundation-on-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/ML-18501-MaturityStages-1091x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we give an overview of a well-established generative AI foundation, dive into its components, and present an end-to-end perspective. We look at different operating models and explore how such a foundation can operate within those boundaries. Lastly, we present a maturity model that helps enterprises assess their evolution path.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="fb70e4ee6ff898bf0bb9aeebd4156917448a7068"
                        open
                      >
                        <summary class="article-expander__title">Using Amazon OpenSearch ML connector APIs</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/using-amazon-opensearch-ml-connector-apis/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/19/ML-17073_arch-diagram-1-910x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>OpenSearch offers a wide range of third-party machine learning (ML) connectors to support this augmentation. This post highlights two of these third-party ML connectors. The first connector we demonstrate is the Amazon Comprehend connector. In this post, we show you how to use this connector to invoke the LangDetect API to detect the languages of ingested documents. The second connector we demonstrate is the Amazon Bedrock connector to invoke the Amazon Titan Text Embeddings v2 model so that you can create embeddings from ingested documents and perform semantic search.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5c3da5dddd774698cf9ea5a935450a07e68f0cfc"
                        open
                      >
                        <summary class="article-expander__title">Bridging the gap between development and production: Seamless model lifecycle management with Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/bridging-the-gap-between-development-and-production-seamless-model-lifecycle-management-with-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/03/20/ML-17607-2-1260x439.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Amazon Bedrock Model Copy and Model Share features provide a powerful option for managing the lifecycle of an AI application from development to production. In this comprehensive blog post, we&#x27;ll dive deep into the Model Share and Model Copy features, exploring their functionalities, benefits, and practical applications in a typical development-to-production scenario.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://blog.thestateofme.com/?p&#x3D;6280"
                        open
                      >
                        <summary class="article-expander__title">Battery Bother</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://blog.thestateofme.com/2025/05/30/battery-bother/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/05/topdon_replace.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>TL;DR I was foolish to believe that paying a premium for a battery with a 5y guarantee would actually get me a battery that lasted 5y :( Background The original battery in my 2010 XC60 died after a little over 5y. I replaced it with an Exide EA852 from Tayna that lasted a bit over […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6280"
                        open
                      >
                        <summary class="article-expander__title">Battery Bother</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/05/30/battery-bother/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/05/topdon_replace.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>TL;DR I was foolish to believe that paying a premium for a battery with a 5y guarantee would actually get me a battery that lasted 5y :( Background The original battery in my 2010 XC60 died after a little over 5y. I replaced it with an Exide EA852 from Tayna that lasted a bit over […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-29 datetime="2025-05-29T21:16:44.000Z">2025-05-29</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-29 datetime="2025-05-29T21:16:44.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="3bb4bbe5b235420c492617a3d2121b3ebb163040"
                        open
                      >
                        <summary class="article-expander__title">Revolutionizing earth observation with geospatial foundation models on AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/revolutionizing-earth-observation-with-geospatial-foundation-models-on-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/featured-images-ML-18209-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how a leading GeoFM (Clay Foundation’s Clay foundation model available on Hugging Face) can be deployed for large-scale inference and fine-tuning on Amazon SageMaker.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;16
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="227913960e800aac958438d8c82982a0a8e17870"
                        open
                      >
                        <summary class="article-expander__title">Create an agentic RAG application for advanced knowledge discovery with LlamaIndex, and Mistral in Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/create-an-agentic-rag-application-for-advanced-knowledge-discovery-with-llamaindex-and-mistral-in-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/featured-images-ML-17742-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate an example of building an agentic RAG application using the LlamaIndex framework. LlamaIndex is a framework that connects FMs with external data sources. It helps ingest, structure, and retrieve information from databases, APIs, PDFs, and more, enabling the agent and RAG for AI applications. This application serves as a research tool, using the Mistral Large 2 FM on Amazon Bedrock generate responses for the agent flow.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="e12f6c346e449dcd74e7d65f0f4348aea5599fd8"
                        open
                      >
                        <summary class="article-expander__title">Text-to-image basics with Amazon Nova Canvas</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/text-to-image-basics-with-amazon-nova-canvas/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/basicstti-1120x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we focus on the Amazon Nova Canvas image generation model. We then provide an overview of the image generation process (diffusion) and dive deep into the input parameters for text-to-image generation with Amazon Nova Canvas.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="f4ad59727833b77a21e74fb047eedefddd145e94"
                        open
                      >
                        <summary class="article-expander__title">Real-world applications of Amazon Nova Canvas for interior design and product photography</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/real-world-applications-of-amazon-nova-canvas-for-interior-design-and-product-photography/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/canvasph-1120x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how Amazon Nova Canvas can solve real-world business challenges through advanced image generation techniques. We focus on two specific use cases that demonstrate the power and flexibility of this technology: interior design and product photography.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-28 datetime="2025-05-28T18:39:06.000Z">2025-05-28</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-28 datetime="2025-05-28T18:39:06.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="eb0a99c699ae379848f181928b419e9309a439bf"
                        open
                      >
                        <summary class="article-expander__title">Part 3: Building an AI-powered assistant for investment research with multi-agent collaboration in Amazon Bedrock and Amazon Bedrock Data Automation</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/part-3-building-an-ai-powered-assistant-for-investment-research-with-multi-agent-collaboration-in-amazon-bedrock-and-amazon-bedrock-data-automation/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/15/technical.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we walk through how to build a multi-agent investment research assistant using the multi-agent collaboration capability of Amazon Bedrock. Our solution demonstrates how a team of specialized AI agents can work together to analyze financial news, evaluate stock performance, optimize portfolio allocations, and deliver comprehensive investment insights—all orchestrated through a unified, natural language interface.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6b4b3ddeb038bf71268875a066a75dadfacb5a97"
                        open
                      >
                        <summary class="article-expander__title">A generative AI prototype with Amazon Bedrock transforms life sciences and the genome analysis process</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/a-generative-ai-prototype-with-amazon-bedrock-transforms-life-sciences-and-the-genome-analysis-process/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/16/ML-16693-arch-diag-Image-001-1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post explores deploying a text-to-SQL pipeline using generative AI models and Amazon Bedrock to ask natural language questions to a genomics database. We demonstrate how to implement an AI assistant web interface with AWS Amplify and explain the prompt engineering strategies adopted to generate the SQL queries. Finally, we present instructions to deploy the service in your own AWS account.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="018494f0dc6de7f5d73496137436311d74f01036"
                        open
                      >
                        <summary class="article-expander__title">Gemma 3 27B model now available on Amazon Bedrock Marketplace and Amazon SageMaker JumpStart</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/gemma-3-27b-model-now-available-on-amazon-bedrock-marketplace-and-amazon-sagemaker-jumpstart/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/28/featured-images-ML-18880-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>We are excited to announce the availability of Gemma 3 27B Instruct models through Amazon Bedrock Marketplace and Amazon SageMaker JumpStart. In this post, we show you how to get started with Gemma 3 27B Instruct on both Amazon Bedrock Marketplace and SageMaker JumpStart, and how to use the model’s powerful instruction-following capabilities in your applications.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="3a07715d8709362ff17a9dd5999533a47fff05a6"
                        open
                      >
                        <summary class="article-expander__title">Building a multimodal RAG based application using Amazon Bedrock Data Automation and Amazon Bedrock Knowledge Bases</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/building-a-multimodal-rag-based-application-using-amazon-bedrock-data-automation-and-amazon-bedrock-knowledge-bases/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/19/ml-18747-arc-diagram.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we walk through building a full-stack application that processes multimodal content using Amazon Bedrock Data Automation, stores the extracted information in an Amazon Bedrock knowledge base, and enables natural language querying through a RAG-based Q&amp;A interface.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="fff8bab4515556e2437cdce5776bfc9deafe52f5"
                        open
                      >
                        <summary class="article-expander__title">Tailoring foundation models for your business needs: A comprehensive guide to RAG, fine-tuning, and hybrid approaches</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/tailoring-foundation-models-for-your-business-needs-a-comprehensive-guide-to-rag-fine-tuning-and-hybrid-approaches/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/07/Screenshot-2025-05-07-at-15.40.11-1197x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show you how to implement and evaluate three powerful techniques for tailoring FMs to your business needs: RAG, fine-tuning, and a hybrid approach combining both methods. We provid ready-to-use code to help you experiment with these approaches and make informed decisions based on your specific use case and dataset.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6eac06ee11a06e22b9c5ae252cc52001146f7347"
                        open
                      >
                        <summary class="article-expander__title">How Rufus doubled their inference speed and handled Prime Day traffic with AWS AI chips and parallel decoding</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-rufus-doubled-their-inference-speed-and-handled-prime-day-traffic-with-aws-ai-chips-and-parallel-decoding/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/28/featured-images-ML-18346-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Rufus, an AI-powered shopping assistant, relies on many components to deliver its customer experience including a foundation LLM (for response generation) and a query planner (QP) model for query classification and retrieval enhancement. This post focuses on how the QP model used draft centric speculative decoding (SD)—also called parallel decoding—with AWS AI chips to meet the demands of Prime Day. By combining parallel decoding with AWS Trainium and Inferentia chips, Rufus achieved two times faster response times, a 50% reduction in inference costs, and seamless scalability during peak traffic.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-27 datetime="2025-05-27T20:22:24.000Z">2025-05-27</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-27 datetime="2025-05-27T20:22:24.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="199eef1e439f0bd41b70ead937e65266f9998de3"
                        open
                      >
                        <summary class="article-expander__title">New Amazon Bedrock Data Automation capabilities streamline video and audio analysis</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/new-amazon-bedrock-data-automation-capabilities-streamline-video-and-audio-analysis/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/27/featured-images-ML-18353-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Amazon Bedrock Data Automation helps organizations streamline development and boost efficiency through customizable, multimodal analytics. It eliminates the heavy lifting of unstructured content processing at scale, whether for video or audio. The new capabilities make it faster to extract tailored, generative AI-powered insights like scene summaries, key topics, and customer intents from video and audio. This unlocks the value of unstructured content for use cases such as improving sales productivity and enhancing customer experience.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="7be52456e9b72716d754a63c027f22d516211526"
                        open
                      >
                        <summary class="article-expander__title">GuardianGamer scales family-safe cloud gaming with AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/guardiangamer-scales-family-safe-cloud-gaming-with-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/23/featured-images-ml-18855-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we share how GuardianGamer uses AWS services including Amazon Nova and Amazon Bedrock to deliver a scalable and efficient supervision platform. The team uses Amazon Nova for intelligent narrative generation to provide parents with meaningful insights into their children’s gaming activities and social interactions, while maintaining a non-intrusive approach to monitoring.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-26 datetime="2025-05-26T02:04:54.000Z">2025-05-26</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-26 datetime="2025-05-26T02:04:54.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1642"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #478</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-478/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com Security and SRE: How Datadog’s combined approach aims to tackle security and reliability challenges Datadog has fully merged their SRE and Security teams. In this post, we’ll look at essential elements of SRE and security, the benefits we’ve realized by combining the two disciplines, and what that approach looks like for us. […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-25 datetime="2025-05-25T00:00:00.000Z">2025-05-25</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-25 datetime="2025-05-25T00:00:00.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Toby Liu</button>
                  <a class="source-heading__link" href="https://liuning0820.github.io/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://liuning0820.github.io/2025/05/25/public-ollama-models.html"
                        open
                      >
                        <summary class="article-expander__title">Public Ollama Models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://liuning0820.github.io/2025/05/25/public-ollama-models.html">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Public Ollama Models 20250525 How to chat with Ollama models Select an IP and model from the table below, then use them in this command: # Start a conversation with a model # Replace &lt;IP&gt; with an IP from the table below # Replace &lt;MODEL&gt; with one of the models listed for that IP curl -X POST http://&lt;IP&gt;:11434/api/chat -d &#x27;{ &quot;model&quot;: &quot;&lt;MODEL&gt;&quot;, &quot;messages&quot;: [{ &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello, how are you?&quot; }] }&#x27; Available Models IP Models 123.60.64.205 llama3.2:3b-instruct-q5_K_M,deepseek-r1:1.5b 101.132.74.29 llama3.2:3b-instruct-q5_K_M 139.196.196.43 qwen3:32b,qwen3:30b-a3b,qwen2.5:72b-instruct,deepseek-r1:70b 223.166.61.66 qwen3:4b,qwen3:32b,mxbai-embed-large:latest,bge-m3:latest,nomic-embed-text:latest,qwen2.5-coder:32b,qwen2.5-coder:14b,qwen2.5:32b,qwen2.5:latest,mistral-small3.1:latest,codellama:13b,codellama:34b,codellama:70b,qwq:latest,deepseek-v2:16b,deepseek-coder-v2:latest,gemma3:12b,gemma3:latest,qwen2.5:3b,gemma3:1b,deepseek-r1:14b,deepseek-r1:32b,deepseek-r1:8b,deepseek-r1:7b,deepseek-r1:1.5b 106.75.235.214 llama3.1:8b,gemma3:27b,qwq:latest,deepseek-r1:70b 117.50.171.129 qwq:latest,qwen2.5-coder:32b 117.50.180.35 bge-m3:latest 116.232.26.17 qwen3:0.6b,qwen3:1.7b 117.50.176.34 qwen2.5:1.5b,qwen2.5:7b,qwen2.5:14b 222.64.131.253 llama3.2:3b-instruct-q5_K_M,qwen2.5:32b-instruct-q4_K_M,qwq:32b-q4_K_M,qwen2.5:32b,qwen2.5-coder:14b,sqlcoder:15b,deepseek-r1:14b,qwen2.5:14b,bge-m3:567m,qwen2.5:7b,nomic-embed-text:latest,qwen2.5:0.5b 123.60.5.218 llama3-backup:latest,mario:latest,llama3.2:latest,llama3.2:3b-instruct-q5_K_M,deepseek-r1:8b 218.1.223.134 llama3.2:3b-instruct-q5_K_M,smollm2:135m,deepseek-r1:1.5b,deepseek-r1:7b,deepseek-r1:8b 101.132.88.19 nomic-embed-text:latest,llama3.2:3b,llama3.2:1b,deepseek-r1:1.5b 114.95.209.211 nomic-embed-text:latest,qwen2.5-coder:latest,deepseek-r1:7b Disclaimer These Ollama model endpoints are publicly exposed interfaces found on the internet. They are listed here for informational purposes only. Please be aware that: These endpoints are not maintained or controlled by us The availability and stability of these services cannot be guaranteed Use these services at your own risk We take no responsibility for any issues or damages that may arise from using these endpoints 免责声明 本文列出的 Ollama 模型接口均来自互联网上公开暴露的端点。请注意： 这些端点并非由我们维护或控制 无法保证这些服务的可用性和稳定性 使用这些服务需自行承担风险 对于使用这些端点可能产生的任何问题或损失，我们不承担任何责任</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-23 datetime="2025-05-23T16:02:19.000Z">2025-05-23</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-23 datetime="2025-05-23T16:02:19.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="21066146982c3823b42b1b8a93bd9f30e8b4a272"
                        open
                      >
                        <summary class="article-expander__title">Principal Financial Group increases Voice Virtual Assistant performance using Genesys, Amazon Lex, and Amazon QuickSight</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/principal-financial-group-increases-voice-virtual-assistant-performance-using-genesys-amazon-lex-and-amazon-quicksight/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/23/featured-images-ML-17823-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how Principal used this opportunity to build an integrated voice VA reporting and analytics solution using an Amazon QuickSight dashboard.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-22 datetime="2025-05-22T16:43:07.000Z">2025-05-22</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-22 datetime="2025-05-22T16:43:07.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="545be771637c99fd9634e31b4d4e23075480378a"
                        open
                      >
                        <summary class="article-expander__title">Optimize query responses with user feedback using Amazon Bedrock embedding and few-shot prompting</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/optimize-query-responses-with-user-feedback-using-amazon-bedrock-embedding-and-few-shot-prompting/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/22/featured-images-ML-17920-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post demonstrates how Amazon Bedrock, combined with a user feedback dataset and few-shot prompting, can refine responses for higher user satisfaction. By using Amazon Titan Text Embeddings v2, we demonstrate a statistically significant improvement in response quality, making it a valuable tool for applications seeking accurate and personalized responses.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="22135586f4a2581be94eb7d2108f3b4cffa6c571"
                        open
                      >
                        <summary class="article-expander__title">Boosting team productivity with Amazon Q Business Microsoft 365 integrations for Microsoft 365 Outlook and Word</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/boosting-team-productivity-with-amazon-q-business-microsoft-365-integrations-for-microsoft-365-outlook-and-word/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/22/featured-images-ML-18481-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Amazon Q Business integration with Microsoft 365 applications offers powerful AI assistance directly within the tools that your team already uses daily. In this post, we explore how these integrations for Outlook and Word can transform your workflow.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>

    <footer>
      <a class="footer-link" href="https://github.com/liuning0820/rss-reader/actions/runs/15788736503">
        <time id="build-timestamp" datetime="2025-06-20T22:16:22.191Z">2025-06-20T22:16:22.191Z</time>
      </a>
      <a class="footer-link" href="https://github.com/osmoscraft/osmosfeed">osmosfeed 1.15.1</a>
    </footer>
    <script src="index.js?v1.14.4"></script>
    <!-- %before-body-end.html% -->
  </body>

</html>