<!DOCTYPE html>
<html lang="en">

  <head>
    <title>RSS Feed Reader</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="RSS Feed Reader" href="feed.atom" />
    <link href="index.css?v1.14.4" rel="stylesheet" />
    <!-- %before-head-end.html% -->
  </head>

  <body>
    <!-- %after-body-begin.html% -->
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-09 datetime="2025-06-09T15:50:24.000Z">2025-06-09</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-09 datetime="2025-06-09T15:50:24.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="e097c4af840d23d119a36dedaf3df20f8118cf0f"
                        open
                      >
                        <summary class="article-expander__title">Building intelligent AI voice agents with Pipecat and Amazon Bedrock ‚Äì Part 1</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/building-intelligent-ai-voice-agents-with-pipecat-and-amazon-bedrock-part-1/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/10/Cover-Voice-AI-agents-1120x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this series of posts, you will learn how to build intelligent AI voice agents using Pipecat, an open-source framework for voice and multimodal conversational AI agents, with foundation models on Amazon Bedrock. It includes high-level reference architectures, best practices and code samples to guide your implementation.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5ba9900fe962810f04b60366ba90d3a8a4753c61"
                        open
                      >
                        <summary class="article-expander__title">Stream multi-channel audio to Amazon Transcribe using the Web Audio API</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/stream-multi-channel-audio-to-amazon-transcribe-using-the-web-audio-api/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/01/Picture1-17.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore the implementation details of a web application that uses the browser‚Äôs Web Audio API and Amazon Transcribe streaming to enable real-time dual-channel transcription. By using the combination of AudioContext, ChannelMergerNode, and AudioWorklet, we were able to seamlessly process and encode the audio data from two microphones before sending it to Amazon Transcribe for transcription.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="db12f9abc38a429c3b44d3b3b6e2c6d4f43aa4aa"
                        open
                      >
                        <summary class="article-expander__title">How Kepler democratized AI access and enhanced client services with Amazon Q Business</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-kepler-democratized-ai-access-and-enhanced-client-services-with-amazon-q-business/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/03/ML-18968-image-1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>At Kepler, a global full-service digital marketing agency serving Fortune 500 brands, we understand the delicate balance between creative marketing strategies and data-driven precision. In this post, we share how implementing Amazon Q Business transformed our operations by democratizing AI access across our organization while maintaining stringent security standards, resulting in an average savings of 2.7 hours per week per employee in manual work and improved client service delivery.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6339"
                        open
                      >
                        <summary class="article-expander__title">Dart binaries in Python packages</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/06/09/dart-binaries-in-python-packages/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://s0.wp.com/i/blank.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>TL;DR PyPI provides a neat way of distributing binaries from other languages, and Python venvs make it easy to run different versions side by side. This post takes a look at how to do that with Dart, and the next steps necessary to do a proper job of it. Background A few days ago I [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1649"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #480</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-480/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com A message from our sponsor, PagerDuty: üîç Notable PagerDuty shift: Full incident management now spans all paid tiers. The upgraded Slack-first and Teams-first experience means fewer tools to juggle during incidents. Only leveraging PagerDuty for basic alerting? Time to check out what‚Äôs newly available in your plan! https://fnf.dev/4dZ5V36 You can‚Äôt prevent your [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-06 datetime="2025-06-06T17:34:31.000Z">2025-06-06</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-06 datetime="2025-06-06T17:34:31.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5a6a5e152dd1e382b4fd03a685f16a6d3400e297"
                        open
                      >
                        <summary class="article-expander__title">Build a serverless audio summarization solution with Amazon Bedrock and Whisper</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-serverless-audio-summarization-solution-with-amazon-bedrock-and-whisper/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/19/Picture2-4-crop.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to use the Open AI Whisper foundation model (FM) Whisper Large V3 Turbo, available in Amazon Bedrock Marketplace, which offers access to over 140 models through a dedicated offering, to produce near real-time transcription. These transcriptions are then processed by Amazon Bedrock for summarization and redaction of sensitive information.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="ecc7ca1bb5896b73806a97065e5af80edbfea514"
                        open
                      >
                        <summary class="article-expander__title">Implement semantic video search using open source large vision models on Amazon SageMaker and Amazon OpenSearch Serverless</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/implement-semantic-video-search-using-open-source-large-vision-models-on-amazon-sagemaker-and-amazon-opensearch-serverless/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/07/fig1-1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to use large vision models (LVMs) for semantic video search using natural language and image queries. We introduce some use case-specific methods, such as temporal frame smoothing and clustering, to enhance the video search performance. Furthermore, we demonstrate the end-to-end functionality of this approach by using both asynchronous and real-time hosting options on Amazon SageMaker AI to perform video, image, and text processing using publicly available LVMs on the Hugging Face Model Hub. Finally, we use Amazon OpenSearch Serverless with its vector engine for low-latency semantic video search.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="e917b802ba8b25de8e0d3191f459fab8b48c3e35"
                        open
                      >
                        <summary class="article-expander__title">Multi-account support for Amazon SageMaker HyperPod task governance</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/multi-account-support-for-amazon-sagemaker-hyperpod-task-governance/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/28/access-points-jpmc.drawio-2-701x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we discuss how an enterprise with multiple accounts can access a shared Amazon SageMaker HyperPod cluster for running their heterogenous workloads. We use SageMaker HyperPod task governance to enable this feature.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6074fa33042c619e87fded8a1e64a99e6ec76126"
                        open
                      >
                        <summary class="article-expander__title">Build a Text-to-SQL solution for data consistency in generative AI using Amazon Nova</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-text-to-sql-solution-for-data-consistency-in-generative-ai-using-amazon-nova/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/23/ML-17543-arch-diag.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post evaluates the key options for querying data using generative AI, discusses their strengths and limitations, and demonstrates why Text-to-SQL is the best choice for deterministic, schema-specific tasks. We show how to effectively use Text-to-SQL using Amazon Nova, a foundation model (FM) available in Amazon Bedrock, to derive precise and reliable answers from your data.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6328"
                        open
                      >
                        <summary class="article-expander__title">Dealing with Policy Debt</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/06/06/dealing-with-policy-debt/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://s0.wp.com/i/blank.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>TL;DR Start writing down why decisions are made. Future you may thank you. Future other person who‚Äôs wondering what you were thinking may also thank you. Then keep a dependency graph of the things impacted by the decision. It will help unravel what gets woven around it. Background I was at an excellent AFCEA event [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-05 datetime="2025-06-05T16:40:32.000Z">2025-06-05</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-05 datetime="2025-06-05T16:40:32.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="26d9ee9cb82638d9cf710c0c2633411cd20d810e"
                        open
                      >
                        <summary class="article-expander__title">Modernize and migrate on-premises fraud detection machine learning workflows to Amazon SageMaker</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/modernize-and-migrate-on-premises-fraud-detection-machine-learning-workflows-to-amazon-sagemaker/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/22/ML-17395-1-Legacy-architecture-1-796x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Radial is the largest 3PL fulfillment provider, also offering integrated payment, fraud detection, and omnichannel solutions to mid-market and enterprise brands. In this post, we share how Radial optimized the cost and performance of their fraud detection machine learning (ML) applications by modernizing their ML workflow using Amazon SageMaker.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="94e43b5f050984d07a671df4b0b5f596953d31ad"
                        open
                      >
                        <summary class="article-expander__title">Contextual retrieval in Anthropic using Amazon Bedrock Knowledge Bases</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/contextual-retrieval-in-anthropic-using-amazon-bedrock-knowledge-bases/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/05/contextual-retrieval.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Contextual retrieval enhances traditional RAG by adding chunk-specific explanatory context to each chunk before generating embeddings. This approach enriches the vector representation with relevant contextual information, enabling more accurate retrieval of semantically related content when responding to user queries. In this post, we demonstrate how to use contextual retrieval with Anthropic and Amazon Bedrock Knowledge Bases.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="f1c484e234ef857fc38050d28db3464ea042d620"
                        open
                      >
                        <summary class="article-expander__title">Run small language models cost-efficiently with AWS Graviton and Amazon SageMaker AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/run-small-language-models-cost-efficiently-with-aws-graviton-and-amazon-sagemaker-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/04/23/ML-18152-torch-diag.png-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to deploy a small language model on SageMaker AI by extending our pre-built containers to be compatible with AWS Graviton instances. We first provide an overview of the solution, and then provide detailed implementation steps to help you get started. You can find the example notebook in the GitHub repo.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-04 datetime="2025-06-04T21:20:47.000Z">2025-06-04</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-04 datetime="2025-06-04T21:20:47.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="9e02f996c5e3c80f14860bee9c7951901afe8e1e"
                        open
                      >
                        <summary class="article-expander__title">Impel enhances automotive dealership customer experience with fine-tuned LLMs on Amazon SageMaker</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/impel-enhances-automotive-dealership-customer-experience-with-fine-tuned-llms-on-amazon-sagemaker/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/27/ml-18410-arch-diag.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we share how Impel enhances the automotive dealership customer experience with fine-tuned LLMs on SageMaker.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="259f623956d3dd5819ce7d6bd0a6b9fc6ffa7876"
                        open
                      >
                        <summary class="article-expander__title">How climate tech startups are building foundation models with Amazon SageMaker HyperPod</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-climate-tech-startups-are-building-foundation-models-with-amazon-sagemaker-hyperpod/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/27/AGIClimate-image-1-1260x607.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show how climate tech startups are developing foundation models (FMs) that use extensive environmental datasets to tackle issues such as carbon capture, carbon-negative fuels, new materials design for microplastics destruction, and ecosystem preservation. These specialized models require advanced computational capabilities to process and analyze vast amounts of data effectively.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="90d51716ebb0bf0a6e473917ac8f73f19d948ed5"
                        open
                      >
                        <summary class="article-expander__title">Supercharge your development with Claude Code and Amazon Bedrock prompt caching</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/supercharge-your-development-with-claude-code-and-amazon-bedrock-prompt-caching/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/04/supercharge-claude.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we&#x27;ll explore how to combine Amazon Bedrock prompt caching with Claude Code‚Äîa coding agent released by Anthropic that is now generally available. This powerful combination transforms your development workflow by delivering lightning-fast responses from reducing inference response latency, as well as lowering input token costs.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-03 datetime="2025-06-03T16:53:40.000Z">2025-06-03</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-03 datetime="2025-06-03T16:53:40.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="13977db91c0667df2c60f5413703e78f125f9415"
                        open
                      >
                        <summary class="article-expander__title">Unlocking the power of Model Context Protocol (MCP) on AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/unlocking-the-power-of-model-context-protocol-mcp-on-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/23/ML-18605-bedrock-kb-architecture-884x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>We‚Äôve witnessed remarkable advances in model capabilities as generative AI companies have invested in developing their offerings. Language models such as Anthropic‚Äôs Claude Opus 4 &amp; Sonnet 4, Amazon Nova, and Amazon Bedrock can reason, write, and generate responses with increasing sophistication. But even as these models grow more powerful, they can only work with [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;16
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="17c1ad8a3aa1ddac84328d052610f759cc45c367"
                        open
                      >
                        <summary class="article-expander__title">Build a scalable AI assistant to help refugees using AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-scalable-ai-assistant-to-help-refugees-using-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/15/photo_2025-05-14_14-28-29-AG-250515-1-1091x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>The Danish humanitarian organization Bevar Ukraine has developed a comprehensive virtual generative AI-powered assistant called Victor, aimed at addressing the pressing needs of Ukrainian refugees integrating into Danish society. This post details our technical implementation using AWS services to create a scalable, multilingual AI assistant system that provides automated assistance while maintaining data security and GDPR compliance.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6c5a159320be3c2e07fe7b729cc907f5a0aa84d4"
                        open
                      >
                        <summary class="article-expander__title">Enhanced diagnostics flow with LLM and Amazon Bedrock agent integration</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/enhanced-diagnostics-flow-with-llm-and-amazon-bedrock-agent-integration/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/20/Noodoe-GenAI-Data-Flow.drawio-870x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how Noodoe uses AI and Amazon Bedrock to optimize EV charging operations. By integrating LLMs, Noodoe enhances station diagnostics, enables dynamic pricing, and delivers multilingual support. These innovations reduce downtime, maximize efficiency, and improve sustainability. Read on to discover how AI is transforming EV charging management.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6317"
                        open
                      >
                        <summary class="article-expander__title">Using a Python venv to run different versions of CMake</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/06/03/using-a-python-venv-to-run-different-versions-of-cmake/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://s0.wp.com/i/blank.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Sometimes I need an older or newer version of CMake to the one installed by the system package manager on whatever I‚Äôm using, and I‚Äôve found using a Python venv provides an easy way to do that. It‚Äôs all facilitated by the fact that CMake is a PyPI package [1]. For example, my Kubuntu desktop [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-02 datetime="2025-06-02T17:39:51.000Z">2025-06-02</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-02 datetime="2025-06-02T17:39:51.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="bbda6d388effd5a44bca2d930f35ee4d1f137b85"
                        open
                      >
                        <summary class="article-expander__title">Build GraphRAG applications using Amazon Bedrock Knowledge Bases</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-graphrag-applications-using-amazon-bedrock-knowledge-bases/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/19/ML-18340_002_architecture.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how to use Graph-based Retrieval-Augmented Generation (GraphRAG) in Amazon Bedrock Knowledge Bases to build intelligent applications. Unlike traditional vector search, which retrieves documents based on similarity scores, knowledge graphs encode relationships between entities, allowing large language models (LLMs) to retrieve information with context-aware reasoning.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="ddce93902a4813aa526a5a42e972c4eebe188fa0"
                        open
                      >
                        <summary class="article-expander__title">Streamline personalization development: How automated ML workflows accelerate Amazon Personalize implementation</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/streamline-personalization-development-how-automated-ml-workflows-accelerate-amazon-personalize-implementation/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/03/ML-17195-Picture1-1260x587.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This blog post presents an MLOps solution that uses AWS Cloud Development Kit (AWS CDK) and services like AWS Step Functions, Amazon EventBridge and Amazon Personalize to automate provisioning resources for data preparation, model training, deployment, and monitoring for Amazon Personalize.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="dc55c0b49c875a811a3e114c791325bab95ee403"
                        open
                      >
                        <summary class="article-expander__title">Fast-track SOP processing using Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/fast-track-sop-processing-using-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/16/ML-17198-arch-diag-Image-003-1152x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>When a regulatory body like the US Food and Drug Administration (FDA) introduces changes to regulations, organizations are required to evaluate the changes against their internal SOPs. When necessary, they must update their SOPs to align with the regulation changes and maintain compliance. In this post, we show different approaches using Amazon Bedrock to identify relationships between regulation changes and SOPs.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;18
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6282"
                        open
                      >
                        <summary class="article-expander__title">May 2025</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/06/02/may-2025/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/05/pups_202505.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Pupdate The fair weather has (mostly) continued, which allowed for some nice long walks. Milo turned four at the start of the month :) Brussels The end of the month brought the half term holiday, and Mrs S wanted to spend the first weekend away somewhere. Brussels quickly made the top of the list after [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://blog.thestateofme.com/?p&#x3D;6282"
                        open
                      >
                        <summary class="article-expander__title">May 2025</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://blog.thestateofme.com/2025/06/02/may-2025/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/05/pups_202505.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Pupdate The fair weather has (mostly) continued, which allowed for some nice long walks. Milo turned four at the start of the month :) Brussels The end of the month brought the half term holiday, and Mrs S wanted to spend the first weekend away somewhere. Brussels quickly made the top of the list after [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1644"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #479</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-479/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com Automatic rollbacks are a last resort Rollbacks don‚Äôt always return you to a previous system state. They can return you to a state you‚Äôve never tested or operated before. ¬†¬†Steve Fenton ‚Äî Octopus Deploy Burn rate is a better error rate This article explains the math of burn rate alerting and gives [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-30 datetime="2025-05-30T17:27:16.000Z">2025-05-30</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-30 datetime="2025-05-30T17:27:16.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="d7f85bb395e5d94da0c05bbf126af35c78256cb2"
                        open
                      >
                        <summary class="article-expander__title">Deploy Amazon SageMaker Projects with Terraform Cloud</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/deploy-amazon-sagemaker-projects-with-terraform-cloud/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/30/deploy-sagemaker-projects-terraform.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post you define, deploy, and provision a SageMaker Project custom template purely in Terraform. With no dependencies on other IaC tools, you can now enable SageMaker Projects strictly within your Terraform Enterprise infrastructure.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="18d316f7d52dafde0260f4c03c9632fd3035c21e"
                        open
                      >
                        <summary class="article-expander__title">How ZURU improved the accuracy of floor plan generation by 109% using Amazon Bedrock and Amazon SageMaker</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-zuru-improved-the-accuracy-of-floor-plan-generation-by-109-using-amazon-bedrock-and-amazon-sagemaker/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/14/PE-workflow-highres-1260x600.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>ZURU collaborated with AWS Generative AI Innovation Center and AWS Professional Services to implement a more accurate text-to-floor plan generator using generative AI. In this post, we show you why a solution using a large language model (LLM) was chosen. We explore how model selection, prompt engineering, and fine-tuning can be used to improve results.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="b462012de270e591499ba1c159ea3e9bfda36da6"
                        open
                      >
                        <summary class="article-expander__title">Going beyond AI assistants: Examples from Amazon.com reinventing industries with generative AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/going-beyond-ai-assistants-examples-from-amazon-com-reinventing-industries-with-generative-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/16/Picture8-blog17678-1-1135x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Non-conversational applications offer unique advantages such as higher latency tolerance, batch processing, and caching, but their autonomous nature requires stronger guardrails and exhaustive quality assurance compared to conversational applications, which benefit from real-time user feedback and supervision. This post examines four diverse Amazon.com examples of such generative AI applications.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="4b216781c496ceff2fc13b51dfa10b08ff663497"
                        open
                      >
                        <summary class="article-expander__title">Architect a mature generative AI foundation on AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/architect-a-mature-generative-ai-foundation-on-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/ML-18501-MaturityStages-1091x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we give an overview of a well-established generative AI foundation, dive into its components, and present an end-to-end perspective. We look at different operating models and explore how such a foundation can operate within those boundaries. Lastly, we present a maturity model that helps enterprises assess their evolution path.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="fb70e4ee6ff898bf0bb9aeebd4156917448a7068"
                        open
                      >
                        <summary class="article-expander__title">Using Amazon OpenSearch ML connector APIs</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/using-amazon-opensearch-ml-connector-apis/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/19/ML-17073_arch-diagram-1-910x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>OpenSearch offers a wide range of third-party machine learning (ML) connectors to support this augmentation. This post highlights two of these third-party ML connectors. The first connector we demonstrate is the Amazon Comprehend connector. In this post, we show you how to use this connector to invoke the LangDetect API to detect the languages of ingested documents. The second connector we demonstrate is the Amazon Bedrock connector to invoke the Amazon Titan Text Embeddings v2 model so that you can create embeddings from ingested documents and perform semantic search.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5c3da5dddd774698cf9ea5a935450a07e68f0cfc"
                        open
                      >
                        <summary class="article-expander__title">Bridging the gap between development and production: Seamless model lifecycle management with Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/bridging-the-gap-between-development-and-production-seamless-model-lifecycle-management-with-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/03/20/ML-17607-2-1260x439.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Amazon Bedrock Model Copy and Model Share features provide a powerful option for managing the lifecycle of an AI application from development to production. In this comprehensive blog post, we&#x27;ll dive deep into the Model Share and Model¬†Copy features, exploring their functionalities, benefits, and practical applications in a typical development-to-production scenario.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://blog.thestateofme.com/?p&#x3D;6280"
                        open
                      >
                        <summary class="article-expander__title">Battery Bother</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://blog.thestateofme.com/2025/05/30/battery-bother/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/05/topdon_replace.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>TL;DR I was foolish to believe that paying a premium for a battery with a 5y guarantee would actually get me a battery that lasted 5y :( Background The original battery in my 2010 XC60 died after a little over 5y. I replaced it with an Exide EA852 from Tayna that lasted a bit over [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6280"
                        open
                      >
                        <summary class="article-expander__title">Battery Bother</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/05/30/battery-bother/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/05/topdon_replace.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>TL;DR I was foolish to believe that paying a premium for a battery with a 5y guarantee would actually get me a battery that lasted 5y :( Background The original battery in my 2010 XC60 died after a little over 5y. I replaced it with an Exide EA852 from Tayna that lasted a bit over [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-29 datetime="2025-05-29T21:16:44.000Z">2025-05-29</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-29 datetime="2025-05-29T21:16:44.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="3bb4bbe5b235420c492617a3d2121b3ebb163040"
                        open
                      >
                        <summary class="article-expander__title">Revolutionizing earth observation with geospatial foundation models on AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/revolutionizing-earth-observation-with-geospatial-foundation-models-on-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/featured-images-ML-18209-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how a leading GeoFM (Clay Foundation‚Äôs Clay foundation model available on Hugging Face) can be deployed for large-scale inference and fine-tuning on Amazon SageMaker.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;16
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="227913960e800aac958438d8c82982a0a8e17870"
                        open
                      >
                        <summary class="article-expander__title">Create an agentic RAG application for advanced knowledge discovery with LlamaIndex, and Mistral in Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/create-an-agentic-rag-application-for-advanced-knowledge-discovery-with-llamaindex-and-mistral-in-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/featured-images-ML-17742-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate an example of building an agentic RAG application using the LlamaIndex framework. LlamaIndex is a framework that connects FMs with external data sources. It helps ingest, structure, and retrieve information from databases, APIs, PDFs, and more, enabling the agent and RAG for AI applications. This application serves as a research tool, using the Mistral Large 2 FM on Amazon Bedrock generate responses for the agent flow.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="e12f6c346e449dcd74e7d65f0f4348aea5599fd8"
                        open
                      >
                        <summary class="article-expander__title">Text-to-image basics with Amazon Nova Canvas</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/text-to-image-basics-with-amazon-nova-canvas/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/basicstti-1120x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we focus on the Amazon Nova Canvas image generation model. We then provide an overview of the image generation process (diffusion) and dive deep into the input parameters for text-to-image generation with Amazon Nova Canvas.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="f4ad59727833b77a21e74fb047eedefddd145e94"
                        open
                      >
                        <summary class="article-expander__title">Real-world applications of Amazon Nova Canvas for interior design and product photography</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/real-world-applications-of-amazon-nova-canvas-for-interior-design-and-product-photography/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/29/canvasph-1120x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how Amazon Nova Canvas can solve real-world business challenges through advanced image generation techniques. We focus on two specific use cases that demonstrate the power and flexibility of this technology: interior design and product photography.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-28 datetime="2025-05-28T18:39:06.000Z">2025-05-28</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-28 datetime="2025-05-28T18:39:06.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="eb0a99c699ae379848f181928b419e9309a439bf"
                        open
                      >
                        <summary class="article-expander__title">Part 3: Building an AI-powered assistant for investment research with multi-agent collaboration in Amazon Bedrock and Amazon Bedrock Data Automation</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/part-3-building-an-ai-powered-assistant-for-investment-research-with-multi-agent-collaboration-in-amazon-bedrock-and-amazon-bedrock-data-automation/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/15/technical.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we walk through how to build a multi-agent investment research assistant using the multi-agent collaboration capability of Amazon Bedrock. Our solution demonstrates how a team of specialized AI agents can work together to analyze financial news, evaluate stock performance, optimize portfolio allocations, and deliver comprehensive investment insights‚Äîall orchestrated through a unified, natural language interface.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6b4b3ddeb038bf71268875a066a75dadfacb5a97"
                        open
                      >
                        <summary class="article-expander__title">A generative AI prototype with Amazon Bedrock transforms life sciences and the genome analysis process</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/a-generative-ai-prototype-with-amazon-bedrock-transforms-life-sciences-and-the-genome-analysis-process/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/16/ML-16693-arch-diag-Image-001-1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post explores deploying a text-to-SQL pipeline using generative AI models and Amazon Bedrock to ask natural language questions to a genomics database. We demonstrate how to implement an AI assistant web interface with AWS Amplify and explain the prompt engineering strategies adopted to generate the SQL queries. Finally, we present instructions to deploy the service in your own AWS account.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="018494f0dc6de7f5d73496137436311d74f01036"
                        open
                      >
                        <summary class="article-expander__title">Gemma 3 27B model now available on Amazon Bedrock Marketplace and Amazon SageMaker JumpStart</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/gemma-3-27b-model-now-available-on-amazon-bedrock-marketplace-and-amazon-sagemaker-jumpstart/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/28/featured-images-ML-18880-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>We are excited to announce the availability of Gemma 3 27B Instruct models through Amazon Bedrock Marketplace and Amazon SageMaker JumpStart. In this post, we show you how to get started with Gemma 3 27B Instruct on both Amazon Bedrock Marketplace and SageMaker JumpStart, and how to use the model‚Äôs powerful instruction-following capabilities in your applications.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="3a07715d8709362ff17a9dd5999533a47fff05a6"
                        open
                      >
                        <summary class="article-expander__title">Building a multimodal RAG based application using Amazon Bedrock Data Automation and Amazon Bedrock Knowledge Bases</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/building-a-multimodal-rag-based-application-using-amazon-bedrock-data-automation-and-amazon-bedrock-knowledge-bases/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/19/ml-18747-arc-diagram.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we walk through building a full-stack application that processes multimodal content using Amazon Bedrock Data Automation, stores the extracted information in an¬†Amazon Bedrock knowledge base, and enables natural language querying through a RAG-based Q&amp;A interface.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="fff8bab4515556e2437cdce5776bfc9deafe52f5"
                        open
                      >
                        <summary class="article-expander__title">Tailoring foundation models for your business needs: A comprehensive guide to RAG, fine-tuning, and hybrid approaches</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/tailoring-foundation-models-for-your-business-needs-a-comprehensive-guide-to-rag-fine-tuning-and-hybrid-approaches/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/07/Screenshot-2025-05-07-at-15.40.11-1197x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show you how to implement and evaluate three powerful techniques for tailoring FMs to your business needs: RAG, fine-tuning, and a hybrid approach combining both methods. We provid ready-to-use code to help you experiment with these approaches and make informed decisions based on your specific use case and dataset.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6eac06ee11a06e22b9c5ae252cc52001146f7347"
                        open
                      >
                        <summary class="article-expander__title">How Rufus doubled their inference speed and handled Prime Day traffic with AWS AI chips and parallel decoding</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-rufus-doubled-their-inference-speed-and-handled-prime-day-traffic-with-aws-ai-chips-and-parallel-decoding/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/28/featured-images-ML-18346-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Rufus, an AI-powered shopping assistant, relies on many components to deliver its customer experience including a foundation LLM (for response generation) and a query planner (QP) model for query classification and retrieval enhancement. This post focuses on how the QP model used draft centric speculative decoding (SD)‚Äîalso called parallel decoding‚Äîwith AWS AI chips to meet the demands of Prime Day. By combining parallel decoding with AWS Trainium and Inferentia chips, Rufus achieved two times faster response times, a 50% reduction in inference costs, and seamless scalability during peak traffic.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-27 datetime="2025-05-27T20:22:24.000Z">2025-05-27</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-27 datetime="2025-05-27T20:22:24.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="199eef1e439f0bd41b70ead937e65266f9998de3"
                        open
                      >
                        <summary class="article-expander__title">New Amazon Bedrock Data Automation capabilities streamline video and audio analysis</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/new-amazon-bedrock-data-automation-capabilities-streamline-video-and-audio-analysis/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/27/featured-images-ML-18353-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Amazon Bedrock Data Automation helps organizations streamline development and boost efficiency through customizable, multimodal analytics. It eliminates the heavy lifting of unstructured content processing at scale, whether for video or audio. The new capabilities make it faster to extract tailored, generative AI-powered insights like scene summaries, key topics, and customer intents from video and audio. This unlocks the value of unstructured content for use cases such as improving sales productivity and enhancing customer experience.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="7be52456e9b72716d754a63c027f22d516211526"
                        open
                      >
                        <summary class="article-expander__title">GuardianGamer scales family-safe cloud gaming with AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/guardiangamer-scales-family-safe-cloud-gaming-with-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/23/featured-images-ml-18855-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we share how GuardianGamer uses AWS services including Amazon Nova and Amazon Bedrock to deliver a scalable and efficient supervision platform. The team uses Amazon Nova for intelligent narrative generation to provide parents with meaningful insights into their children‚Äôs gaming activities and social interactions, while maintaining a non-intrusive approach to monitoring.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-26 datetime="2025-05-26T02:04:54.000Z">2025-05-26</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-26 datetime="2025-05-26T02:04:54.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1642"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #478</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-478/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com Security and SRE: How Datadog‚Äôs combined approach aims to tackle security and reliability challenges Datadog has fully merged their SRE and Security teams. In this post, we‚Äôll look at essential elements of SRE and security, the benefits we‚Äôve realized by combining the two disciplines, and what that approach looks like for us. [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-25 datetime="2025-05-25T00:00:00.000Z">2025-05-25</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-25 datetime="2025-05-25T00:00:00.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Toby Liu</button>
                  <a class="source-heading__link" href="https://liuning0820.github.io/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://liuning0820.github.io/2025/05/25/public-ollama-models.html"
                        open
                      >
                        <summary class="article-expander__title">Public Ollama Models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://liuning0820.github.io/2025/05/25/public-ollama-models.html">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Public Ollama Models 20250525 How to chat with Ollama models Select an IP and model from the table below, then use them in this command: # Start a conversation with a model # Replace &lt;IP&gt; with an IP from the table below # Replace &lt;MODEL&gt; with one of the models listed for that IP curl -X POST http://&lt;IP&gt;:11434/api/chat -d &#x27;{ &quot;model&quot;: &quot;&lt;MODEL&gt;&quot;, &quot;messages&quot;: [{ &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello, how are you?&quot; }] }&#x27; Available Models IP Models 123.60.64.205 llama3.2:3b-instruct-q5_K_M,deepseek-r1:1.5b 101.132.74.29 llama3.2:3b-instruct-q5_K_M 139.196.196.43 qwen3:32b,qwen3:30b-a3b,qwen2.5:72b-instruct,deepseek-r1:70b 223.166.61.66 qwen3:4b,qwen3:32b,mxbai-embed-large:latest,bge-m3:latest,nomic-embed-text:latest,qwen2.5-coder:32b,qwen2.5-coder:14b,qwen2.5:32b,qwen2.5:latest,mistral-small3.1:latest,codellama:13b,codellama:34b,codellama:70b,qwq:latest,deepseek-v2:16b,deepseek-coder-v2:latest,gemma3:12b,gemma3:latest,qwen2.5:3b,gemma3:1b,deepseek-r1:14b,deepseek-r1:32b,deepseek-r1:8b,deepseek-r1:7b,deepseek-r1:1.5b 106.75.235.214 llama3.1:8b,gemma3:27b,qwq:latest,deepseek-r1:70b 117.50.171.129 qwq:latest,qwen2.5-coder:32b 117.50.180.35 bge-m3:latest 116.232.26.17 qwen3:0.6b,qwen3:1.7b 117.50.176.34 qwen2.5:1.5b,qwen2.5:7b,qwen2.5:14b 222.64.131.253 llama3.2:3b-instruct-q5_K_M,qwen2.5:32b-instruct-q4_K_M,qwq:32b-q4_K_M,qwen2.5:32b,qwen2.5-coder:14b,sqlcoder:15b,deepseek-r1:14b,qwen2.5:14b,bge-m3:567m,qwen2.5:7b,nomic-embed-text:latest,qwen2.5:0.5b 123.60.5.218 llama3-backup:latest,mario:latest,llama3.2:latest,llama3.2:3b-instruct-q5_K_M,deepseek-r1:8b 218.1.223.134 llama3.2:3b-instruct-q5_K_M,smollm2:135m,deepseek-r1:1.5b,deepseek-r1:7b,deepseek-r1:8b 101.132.88.19 nomic-embed-text:latest,llama3.2:3b,llama3.2:1b,deepseek-r1:1.5b 114.95.209.211 nomic-embed-text:latest,qwen2.5-coder:latest,deepseek-r1:7b Disclaimer These Ollama model endpoints are publicly exposed interfaces found on the internet. They are listed here for informational purposes only. Please be aware that: These endpoints are not maintained or controlled by us The availability and stability of these services cannot be guaranteed Use these services at your own risk We take no responsibility for any issues or damages that may arise from using these endpoints ÂÖçË¥£Â£∞Êòé Êú¨ÊñáÂàóÂá∫ÁöÑ Ollama Ê®°ÂûãÊé•Âè£ÂùáÊù•Ëá™‰∫íËÅîÁΩë‰∏äÂÖ¨ÂºÄÊö¥Èú≤ÁöÑÁ´ØÁÇπ„ÄÇËØ∑Ê≥®ÊÑèÔºö Ëøô‰∫õÁ´ØÁÇπÂπ∂ÈùûÁî±Êàë‰ª¨Áª¥Êä§ÊàñÊéßÂà∂ Êó†Ê≥ï‰øùËØÅËøô‰∫õÊúçÂä°ÁöÑÂèØÁî®ÊÄßÂíåÁ®≥ÂÆöÊÄß ‰ΩøÁî®Ëøô‰∫õÊúçÂä°ÈúÄËá™Ë°åÊâøÊãÖÈ£éÈô© ÂØπ‰∫é‰ΩøÁî®Ëøô‰∫õÁ´ØÁÇπÂèØËÉΩ‰∫ßÁîüÁöÑ‰ªª‰ΩïÈóÆÈ¢òÊàñÊçüÂ§±ÔºåÊàë‰ª¨‰∏çÊâøÊãÖ‰ªª‰ΩïË¥£‰ªª</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-23 datetime="2025-05-23T16:02:19.000Z">2025-05-23</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-23 datetime="2025-05-23T16:02:19.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="21066146982c3823b42b1b8a93bd9f30e8b4a272"
                        open
                      >
                        <summary class="article-expander__title">Principal Financial Group increases Voice Virtual Assistant performance using Genesys, Amazon Lex, and Amazon QuickSight</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/principal-financial-group-increases-voice-virtual-assistant-performance-using-genesys-amazon-lex-and-amazon-quicksight/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/23/featured-images-ML-17823-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how Principal used this opportunity to build an integrated voice VA reporting and analytics solution using an Amazon QuickSight dashboard.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-22 datetime="2025-05-22T16:43:07.000Z">2025-05-22</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-22 datetime="2025-05-22T16:43:07.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="545be771637c99fd9634e31b4d4e23075480378a"
                        open
                      >
                        <summary class="article-expander__title">Optimize query responses with user feedback using Amazon Bedrock embedding and few-shot prompting</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/optimize-query-responses-with-user-feedback-using-amazon-bedrock-embedding-and-few-shot-prompting/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/22/featured-images-ML-17920-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post demonstrates how Amazon Bedrock, combined with a user feedback dataset and few-shot prompting, can refine responses for higher user satisfaction. By using Amazon Titan Text Embeddings v2, we demonstrate a statistically significant improvement in response quality, making it a valuable tool for applications seeking accurate and personalized responses.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="22135586f4a2581be94eb7d2108f3b4cffa6c571"
                        open
                      >
                        <summary class="article-expander__title">Boosting team productivity with Amazon Q Business Microsoft 365 integrations for Microsoft 365 Outlook and Word</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/boosting-team-productivity-with-amazon-q-business-microsoft-365-integrations-for-microsoft-365-outlook-and-word/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/22/featured-images-ML-18481-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Amazon Q Business integration with Microsoft 365 applications offers powerful AI assistance directly within the tools that your team already uses daily. In this post, we explore how these integrations for Outlook and Word can transform your workflow.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-21 datetime="2025-05-21T19:54:03.000Z">2025-05-21</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-21 datetime="2025-05-21T19:54:03.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="122da9844c8487009861561e388917ecd564d08c"
                        open
                      >
                        <summary class="article-expander__title">Integrate Amazon Bedrock Agents with Slack</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/integrate-amazon-bedrock-agents-with-slack/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/12/FeaturedImage-1145x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we present a solution to incorporate Amazon Bedrock Agents in your Slack workspace. We guide you through configuring a Slack workspace, deploying integration components in Amazon Web Services, and using this solution.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="35a3824e39437ee1ba0e5e64bb4d3c293be08d53"
                        open
                      >
                        <summary class="article-expander__title">Secure distributed logging in scalable multi-account deployments using Amazon Bedrock and LangChain</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/secure-distributed-logging-in-scalable-multi-account-deployments-using-amazon-bedrock-and-langchain/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/21/featured-images-ML-18659-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we present a solution for securing distributed logging multi-account deployments using Amazon Bedrock and LangChain.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-20 datetime="2025-05-20T18:40:04.000Z">2025-05-20</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-20 datetime="2025-05-20T18:40:04.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="4a6c86c70e01f7426915a487c56ac46ac4c90e26"
                        open
                      >
                        <summary class="article-expander__title">Build a domain‚Äêaware data preprocessing pipeline: A multi‚Äêagent collaboration approach</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-domain%E2%80%90aware-data-preprocessing-pipeline-a-multi%E2%80%90agent-collaboration-approach/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/12/Architecture_Picture1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we introduce a multi-agent collaboration pipeline for processing unstructured insurance data using Amazon Bedrock, featuring specialized agents for classification, conversion, and metadata extraction. We demonstrate how this domain-aware approach transforms diverse data formats like claims documents, videos, and audio files into metadata-rich outputs that enable fraud detection, customer 360-degree views, and advanced analytics.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;16
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="2a07f5acceb901fa077261135bb44c7807802535"
                        open
                      >
                        <summary class="article-expander__title">Automating complex document processing: How Onity Group built an intelligent solution using Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/automating-complex-document-processing-how-onity-group-built-an-intelligent-solution-using-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/20/onity-1120x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how Onity Group, a financial services company specializing in mortgage servicing and origination, transformed their document processing capabilities using Amazon Bedrock and other AWS services. The solution helped Onity achieve a 50% reduction in document extraction costs while improving overall accuracy by 20% compared to their previous OCR and AI/ML solution.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-19 datetime="2025-05-19T17:41:23.000Z">2025-05-19</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-19 datetime="2025-05-19T17:41:23.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="75a61d5430bb898ce18f5629e9db4a21b6efce4a"
                        open
                      >
                        <summary class="article-expander__title">HERE Technologies boosts developer productivity with new generative AI-powered coding assistant</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/here-technologies-boosts-developer-productivity-with-new-generative-ai-powered-coding-assistant/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/04/24/ml-17998-here-map.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>HERE collaborated with the GenAIIC. Our joint mission was to create an intelligent AI coding assistant that could provide explanations and executable code solutions in response to users‚Äô natural language queries. The requirement was to build a scalable system that could translate natural language questions into HTML code with embedded JavaScript, ready for immediate rendering as an interactive map that users can see on screen.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1640"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #477</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-477/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com Human Error Strikes Again‚Ä¶ or Does It? Why don‚Äôt we look for the root cause of a successful outcome? ¬†¬†Hamed Silatani ‚Äî Uptime Labs How we optimized LLM use for cost, quality, and safety to facilitate writing postmortems They took a great deal of care to avoid the potential pitfalls of using [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-16 datetime="2025-05-16T16:51:03.000Z">2025-05-16</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-16 datetime="2025-05-16T16:51:03.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="7c0ae7779651df7403ff349ccd3e9dba21de1c7a"
                        open
                      >
                        <summary class="article-expander__title">Set up a custom plugin on Amazon Q Business and authenticate with Amazon Cognito to interact with backend systems</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/set-up-a-custom-plugin-on-amazon-q-business-and-authenticate-with-amazon-cognito-to-interact-with-backend-systems/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/02/ml-17088-solution-architecture.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to build a custom plugin with Amazon Q Business for backend integration. This plugin can integrate existing systems, including third-party systems, with little to no development in just weeks and automate critical workflows. Additionally, we show how to safeguard the solution using Amazon Cognito and AWS IAM Identity Center, maintaining the safety and integrity of sensitive data and workflows.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="c066f508ee98a7a883ba339d25588e4cf1cad04a"
                        open
                      >
                        <summary class="article-expander__title">Detect hallucinations for RAG-based systems</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/detect-hallucinations-for-rag-based-systems/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/hallucination_image-1260x375.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post walks you through how to create a basic hallucination detection system for RAG-based applications. We also weigh the pros and cons of different methods in terms of accuracy, precision, recall, and cost.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="ab02c2ba048cee727f635bfba5b103161e04ec46"
                        open
                      >
                        <summary class="article-expander__title">AWS machine learning supports Scuderia Ferrari HP pit stop analysis</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/aws-machine-learning-supports-scuderia-ferrari-hp-pit-stop-analysis/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/15/ML-18723-image001.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Pit crews are trained to operate at optimum efficiency, although measuring their performance has been challenging, until now. In this post, we share how Amazon Web Services (AWS) is helping Scuderia Ferrari HP develop more accurate pit stop analysis techniques using machine learning (ML).</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="3506c6f5650be58ba9bd15c98acba997e7ebb305"
                        open
                      >
                        <summary class="article-expander__title">Accelerate edge AI development with SiMa.ai Edgematic with a seamless AWS integration</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accelerate-edge-ai-development-with-sima-ai-edgematic-with-a-seamless-aws-integration/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/04/16/Image-1-ML17559-1117x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to retrain and quantize a model using SageMaker AI and the SiMa.ai Palette software suite. The goal is to accurately detect individuals in environments where visibility and protective equipment detection are essential for compliance and safety.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;14
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-15 datetime="2025-05-15T19:56:09.000Z">2025-05-15</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-15 datetime="2025-05-15T19:56:09.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5c7e1d518e2b6b677f282e747c9ec8ba35cdae0a"
                        open
                      >
                        <summary class="article-expander__title">How Apoidea Group enhances visual information extraction from banking documents with multimodal models using LLaMA-Factory on Amazon SageMaker HyperPod</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18175-001_vlm_architecture-1260x575.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Building on this foundation of specialized information extraction solutions and using the capabilities of SageMaker HyperPod, we collaborate with APOIDEA Group to explore the use of large vision language models (LVLMs) to further improve table structure recognition performance on banking and financial documents. In this post, we present our work and step-by-step code on fine-tuning the Qwen2-VL-7B-Instruct model using LLaMA-Factory on SageMaker HyperPod.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5a1d027034926735963684b5c8857b2a60e07cba"
                        open
                      >
                        <summary class="article-expander__title">How Qualtrics built Socrates: An AI platform powered by Amazon SageMaker and Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-qualtrics-built-socrates-an-ai-platform-powered-by-amazon-sagemaker-and-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/11/ML-17136-image005-1260x588.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we share how Qualtrics built an AI platform powered by Amazon SageMaker and Amazon Bedrock.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="c2f492c5ef4f95750e6250075eabe260c89c5735"
                        open
                      >
                        <summary class="article-expander__title">Vxceed secures transport operations with Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/vxceed-secures-transport-operations-with-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/Vxceeds-LimoConnect-Q-architecture.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>AWS partnered with Vxceed to support their AI strategy, resulting in the development of LimoConnect Q, an innovative ground transportation management solution. Using AWS services including Amazon Bedrock and Lambda, Vxceed successfully built a secure, AI-powered solution that streamlines trip booking and document processing.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-14 datetime="2025-05-14T15:23:55.000Z">2025-05-14</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-14 datetime="2025-05-14T15:23:55.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="cfc90a1a4fbacee3b7ee8f216a7fb23e12f334a3"
                        open
                      >
                        <summary class="article-expander__title">Cost-effective AI image generation with PixArt-Sigma inference on AWS Trainium and AWS Inferentia</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/cost-effective-ai-image-generation-with-pixart-sigma-inference-on-aws-trainium-and-aws-inferentia/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/14/pixart-trainium-inferentia-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post is the first in a series where we will run multiple diffusion transformers on Trainium and Inferentia-powered instances. In this post, we show how you can deploy PixArt-Sigma to Trainium and Inferentia-powered instances.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="cfc90a1a4fbacee3b7ee8f216a7fb23e12f334a3"
                        open
                      >
                        <summary class="article-expander__title">Cost-effective AI image generation with PixArt-Œ£ inference on AWS Trainium and AWS Inferentia</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/cost-effective-ai-image-generation-with-pixart-%CF%83-inference-on-aws-trainium-and-aws-inferentia/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/14/pixart-trainium-inferentia-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post is the first in a series where we will run multiple diffusion transformers on Trainium and Inferentia-powered instances. In this post, we show how you can deploy PixArt-Sigma to Trainium and Inferentia-powered instances.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="613d3fb9ff5bd12b66c2067eea9ea7934326a3e8"
                        open
                      >
                        <summary class="article-expander__title">Customize DeepSeek-R1 671b model using Amazon SageMaker HyperPod recipes ‚Äì Part 2</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/customize-deepseek-r1-671b-model-using-amazon-sagemaker-hyperpod-recipes-part-2/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/05/Picture2-1260x605.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we use the recipes to fine-tune the original DeepSeek-R1 671b parameter model. We demonstrate this through the step-by-step implementation of these recipes using both SageMaker training jobs and SageMaker HyperPod.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="2766aa0606eb3241b538f6a21b701f1c4ba38182"
                        open
                      >
                        <summary class="article-expander__title">Build a financial research assistant using Amazon Q Business and Amazon QuickSight for generative AI‚Äìpowered insights</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-financial-research-assistant-using-amazon-q-business-and-amazon-quicksight-for-generative-ai-powered-insights/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/05/Picture1-1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show you how Amazon Q Business can help augment your generative AI needs in all the abovementioned use cases and more by answering questions, providing summaries, generating content, and securely completing tasks based on data and information in your enterprise systems.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-13 datetime="2025-05-13T17:33:33.000Z">2025-05-13</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-13 datetime="2025-05-13T17:33:33.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="43f1932e06197826eb958196bb1b7aaa2683f5dd"
                        open
                      >
                        <summary class="article-expander__title">Securing Amazon Bedrock Agents: A guide to safeguarding against indirect prompt injections</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/securing-amazon-bedrock-agents-a-guide-to-safeguarding-against-indirect-prompt-injections/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/13/featured-images-ML-18386-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Generative AI tools have transformed how we work, create, and process information. At Amazon Web Services (AWS), security is our top priority. Therefore, Amazon Bedrock provides comprehensive security controls and best practices to help protect your applications and data. In this post, we explore the security measures and practical strategies provided by Amazon Bedrock Agents to safeguard your AI interactions against indirect prompt injections, making sure that your applications remain both secure and reliable.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="4b5179d063aca37ff510ea5e080fa2bb7691d931"
                        open
                      >
                        <summary class="article-expander__title">Build scalable containerized RAG based generative AI applications in AWS using Amazon EKS with Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-scalable-containerized-rag-based-generative-ai-applications-in-aws-using-amazon-eks-with-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/04/23/eksbedrock-arch-diagram1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate a solution using Amazon Elastic Kubernetes Service (EKS) with Amazon Bedrock to build scalable and containerized RAG solutions for your generative AI applications on AWS while bringing your unstructured user file data to Amazon Bedrock in a straightforward, fast, and secure way.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="177effddf1cba62f5f209b4e1c1bb68cbfb141bb"
                        open
                      >
                        <summary class="article-expander__title">How Hexagon built an AI assistant using AWS generative AI services</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-hexagon-built-an-ai-assistant-using-aws-generative-ai-services/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/04/21/LLMEvaluation-978x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Recognizing the transformative benefits of generative AI for enterprises, we at Hexagon‚Äôs Asset Lifecycle Intelligence division sought to enhance how users interact with our Enterprise Asset Management (EAM) products. Understanding these advantages, we partnered with AWS to embark on a journey to develop HxGN Alix, an AI-powered digital worker using AWS generative AI services. This blog post explores the strategy, development, and implementation of HxGN Alix, demonstrating how a tailored AI solution can drive efficiency and enhance user satisfaction.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-05-12 datetime="2025-05-12T17:34:46.000Z">2025-05-12</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-05-12 datetime="2025-05-12T17:34:46.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >AWS Machine Learning Blog</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="363b3c61905d9d7bad69e82c87e5221adba9bd80"
                        open
                      >
                        <summary class="article-expander__title">Build an intelligent community agent to revolutionize IT support with Amazon Q Business</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-an-intelligent-community-agent-to-revolutionize-it-support-with-amazon-q-business/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/04/28/image001-3.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how your organization can reduce the end-to-end burden of resolving regular challenges experienced by your IT support teams‚Äîfrom understanding errors and reviewing diagnoses, remediation steps, and relevant documentation, to opening external support tickets using common third-party services such as Jira.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="https://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://blog.thestateofme.com/?p&#x3D;6269"
                        open
                      >
                        <summary class="article-expander__title">Milo cancer diary part 19 ‚Äì Four</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://blog.thestateofme.com/2025/05/12/milo-cancer-diary-part-19-four/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/05/milo_bandana_202503.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Milo is four today, another milestone worth celebrating :) Last week he had a scan, which followed 8 weeks after the end of his third (modified) CHOP protocol. The scan was clear, so we‚Äôll be back to NDSR at the start of July. It‚Äôs all a very similar situation to a year ago. Insurance ManyPets [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6269"
                        open
                      >
                        <summary class="article-expander__title">Milo cancer diary part 19 ‚Äì Four</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/05/12/milo-cancer-diary-part-19-four/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/05/milo_bandana_202503.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Milo is four today, another milestone worth celebrating :) Last week he had a scan, which followed 8 weeks after the end of his third (modified) CHOP protocol. The scan was clear, so we‚Äôll be back to NDSR at the start of July. It‚Äôs all a very similar situation to a year ago. Insurance ManyPets [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1638"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #476</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-476/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com Automation and The Substitution Myth The myth is: The underlying and often unexamined assumption for the benefits of automation is the notion that computers/machines are better at some tasks, and humans are better at a different, non-overlapping set of tasks. This article lays out several pitfalls to this approach, with references. ¬†¬†Courtney [‚Ä¶]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>

    <footer>
      <a class="footer-link" href="https://github.com/liuning0820/rss-reader/actions/runs/15556881078">
        <time id="build-timestamp" datetime="2025-06-10T10:19:01.026Z">2025-06-10T10:19:01.026Z</time>
      </a>
      <a class="footer-link" href="https://github.com/osmoscraft/osmosfeed">osmosfeed 1.15.1</a>
    </footer>
    <script src="index.js?v1.14.4"></script>
    <!-- %before-body-end.html% -->
  </body>

</html>