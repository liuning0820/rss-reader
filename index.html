<!DOCTYPE html>
<html lang="en">

  <head>
    <title>RSS Feed Reader</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="RSS Feed Reader" href="feed.atom" />
    <link href="index.css?v1.14.4" rel="stylesheet" />
    <!-- %before-head-end.html% -->
  </head>

  <body>
    <!-- %after-body-begin.html% -->
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-21 datetime="2025-07-21T17:34:21.000Z">2025-07-21</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-21 datetime="2025-07-21T17:34:21.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="91a13d5162821626921c0e5434c13ee09589d5cd"
                        open
                      >
                        <summary class="article-expander__title">Build an AI-powered automated summarization system with Amazon Bedrock and Amazon Transcribe using Terraform</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-an-ai-powered-automated-summarization-system-with-amazon-bedrock-and-amazon-transcribe-using-terraform/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/21/image-1-4-2.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post introduces a serverless meeting summarization system that harnesses the advanced capabilities of Amazon Bedrock and Amazon Transcribe to transform audio recordings into concise, structured, and actionable summaries. By automating this process, organizations can reclaim countless hours while making sure key insights, action items, and decisions are systematically captured and made accessible to stakeholders.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;37
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="d97cb1f0e2b03b5729b50ebb6a890e7fd530fda5"
                        open
                      >
                        <summary class="article-expander__title">Kyruus builds a generative AI provider matching solution on AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/kyruus-builds-a-generative-ai-provider-matching-solution-on-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/07/ML-18861_image-1-1248x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how Kyruus Health uses AWS services to build Guide. We show how Amazon Bedrock, a fully managed service that provides access to foundation models (FMs) from leading AI companies and Amazon through a single API, and Amazon OpenSearch Service, a managed search and analytics service, work together to understand everyday language about health concerns and connect members with the right providers.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;28
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="99397a1f76d1a9c7d7f6b016658a909c98e071c3"
                        open
                      >
                        <summary class="article-expander__title">Use generative AI in Amazon Bedrock for enhanced recommendation generation in equipment maintenance</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/use-generative-ai-in-amazon-bedrock-for-enhanced-recommendation-generation-in-equipment-maintenance/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/21/generative-ai-equipment-maintenance.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In the manufacturing world, valuable insights from service reports often remain underutilized in document storage systems. This post explores how Amazon Web Services (AWS) customers can build a solution that automates the digitisation and extraction of crucial information from many reports using generative AI.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;29
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1665"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #486</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-486/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com A message from our sponsor, Spacelift: IaC Experts! IaCConf Call for Presenters – August 27, 2025 The upcoming IaCConf Spotlight dives into the security and governance challenges of managing infrastructure as code at scale. From embedding security in your pipelines to navigating the realities of open source risk, this event brings together […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-18 datetime="2025-07-18T16:18:32.000Z">2025-07-18</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-18 datetime="2025-07-18T16:18:32.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="207a3853df8297e788fcc08326ea4767d609720e"
                        open
                      >
                        <summary class="article-expander__title">Build real-time travel recommendations using AI agents on Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-real-time-travel-recommendations-using-ai-agents-on-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/14/ML-18056_FeaturedImg.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show how to build a generative AI solution using Amazon Bedrock that creates bespoke holiday packages by combining customer profiles and preferences with real-time pricing data. We demonstrate how to use Amazon Bedrock Knowledge Bases for travel information, Amazon Bedrock Agents for real-time flight details, and Amazon OpenSearch Serverless for efficient package search and retrieval.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;30
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="dd095e79094560bdc0219aa475c48eb9a751a7c4"
                        open
                      >
                        <summary class="article-expander__title">Deploy a full stack voice AI agent with Amazon Nova Sonic</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/deploy-a-full-stack-voice-ai-agent-with-amazon-nova-sonic/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/11/image-4-4-1260x559.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show how to create an AI-powered call center agent for a fictional company called AnyTelco. The agent, named Telly, can handle customer inquiries about plans and services while accessing real-time customer data using custom tools implemented with the Model Context Protocol (MCP) framework.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;29
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="00135b56ce7d068bfe279955dc45cc60357d643f"
                        open
                      >
                        <summary class="article-expander__title">Manage multi-tenant Amazon Bedrock costs using application inference profiles</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/manage-multi-tenant-amazon-bedrock-costs-using-application-inference-profiles/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/11/Slide1.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post explores how to implement a robust monitoring solution for multi-tenant AI deployments using a feature of Amazon Bedrock called application inference profiles. We demonstrate how to create a system that enables granular usage tracking, accurate cost allocation, and dynamic resource management across complex multi-tenant environments.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;30
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-17 datetime="2025-07-17T22:12:26.000Z">2025-07-17</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-17 datetime="2025-07-17T22:12:26.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6a585c5ed36947fd8379ffe5334bb735f4a49e02"
                        open
                      >
                        <summary class="article-expander__title">Evaluating generative AI models with Amazon Nova LLM-as-a-Judge on Amazon SageMaker AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/evaluating-generative-ai-models-with-amazon-nova-llm-as-a-judge-on-amazon-sagemaker-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/ML-19175_FeaturedImg.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Evaluating the performance of large language models (LLMs) goes beyond statistical metrics like perplexity or bilingual evaluation understudy (BLEU) scores. For most real-world generative AI scenarios, it’s crucial to understand whether a model is producing better outputs than a baseline or an earlier iteration. This is especially important for applications such as summarization, content generation, […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;37
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="0185793a426c8fa40d62f8573dfda8378af120f1"
                        open
                      >
                        <summary class="article-expander__title">Building cost-effective RAG applications with Amazon Bedrock Knowledge Bases and Amazon S3 Vectors</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/building-cost-effective-rag-applications-with-amazon-bedrock-knowledge-bases-and-amazon-s3-vectors/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/feature-image-ML-19266-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to integrate Amazon S3 Vectors with Amazon Bedrock Knowledge Bases for RAG applications. You&#x27;ll learn a practical approach to scale your knowledge bases to handle millions of documents while maintaining retrieval quality and using S3 Vectors cost-effective storage.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;32
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="cf0e2dcb31f11f7fc9dde529f5e03eb67f2e04e5"
                        open
                      >
                        <summary class="article-expander__title">Implementing on-demand deployment with customized Amazon Nova models on Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/implementing-on-demand-deployment-with-customized-amazon-nova-models-on-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/17/feature-image-ML-19210-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we walk through the custom model on-demand deployment workflow for Amazon Bedrock and provide step-by-step implementation guides using both the AWS Management Console and APIs or AWS SDKs. We also discuss best practices and considerations for deploying customized Amazon Nova models on Amazon Bedrock.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;30
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="8ff3d6ffcc42ce0c118c5ac38374d452d9d91e63"
                        open
                      >
                        <summary class="article-expander__title">Building enterprise-scale RAG applications with Amazon S3 Vectors and DeepSeek R1 on Amazon SageMaker AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/building-enterprise-scale-rag-applications-with-amazon-s3-vectors-and-deepseek-r1-on-amazon-sagemaker-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/14/ML-18648_FeaturedImg.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Organizations are adopting large language models (LLMs), such as DeepSeek R1, to transform business processes, enhance customer experiences, and drive innovation at unprecedented speed. However, standalone LLMs have key limitations such as hallucinations, outdated knowledge, and no access to proprietary data. Retrieval Augmented Generation (RAG) addresses these gaps by combining semantic search with generative AI, […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;36
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-16 datetime="2025-07-16T22:32:42.000Z">2025-07-16</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-16 datetime="2025-07-16T22:32:42.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="2de7d3933ca4c3f592243660f743458e9a83fb3d"
                        open
                      >
                        <summary class="article-expander__title">Accenture scales video analysis with Amazon Nova and Amazon Bedrock Agents</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accenture-scales-video-analysis-with-amazon-nova-and-amazon-bedrock-agents/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/16/ML-18781_FeaturedImg.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post was written with Ilan Geller, Kamal Mannar, Debasmita Ghosh, and Nakul Aggarwal of Accenture. Video highlights offer a powerful way to boost audience engagement and extend content value for content publishers. These short, high-impact clips capture key moments that drive viewer retention, amplify reach across social media, reinforce brand identity, and open new […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="d459b181b5ff36f14894b2417d772f77e15fefda"
                        open
                      >
                        <summary class="article-expander__title">Deploy conversational agents with Vonage and Amazon Nova Sonic</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/deploy-conversational-agents-with-vonage-and-amazon-nova-sonic/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/14/ML-19208_FeaturedImg.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how developers can integrate Amazon Nova Sonic with the Vonage communications service to build responsive, natural-sounding voice experiences in real time. By combining the Vonage Voice API with the low-latency and expressive speech capabilities of Amazon Nova Sonic, businesses can deploy AI voice agents that deliver more human-like interactions than traditional voice interfaces. These agents can be used as customer support, virtual assistants, and more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;29
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="88fe713fb98339ad011bc8c72d42c9333eb969a0"
                        open
                      >
                        <summary class="article-expander__title">Enabling customers to deliver production-ready AI agents at scale</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/enabling-customers-to-deliver-production-ready-ai-agents-at-scale/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/16/All-days-hero-e1752642848847-1086x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Today, I’m excited to share how we’re bringing this vision to life with new capabilities that address the fundamental aspects of building and deploying agents at scale. These innovations will help you move beyond experiments to production-ready agent systems that can be trusted with your most critical business processes.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;32
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-15 datetime="2025-07-15T22:05:53.000Z">2025-07-15</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-15 datetime="2025-07-15T22:05:53.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="b926c08f19c002c223155095808c4ff9e29ee819"
                        open
                      >
                        <summary class="article-expander__title">Amazon Bedrock Knowledge Bases now supports Amazon OpenSearch Service Managed Cluster as vector store</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-knowledge-bases-now-supports-amazon-opensearch-service-managed-cluster-as-vector-store/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/01/ML-18695-overview-1197x630.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Amazon Bedrock Knowledge Bases has extended its vector store options by enabling support for Amazon OpenSearch Service managed clusters, further strengthening its capabilities as a fully managed Retrieval Augmented Generation (RAG) solution. This enhancement builds on the core functionality of Amazon Bedrock Knowledge Bases , which is designed to seamlessly connect foundation models (FMs) with internal data sources. This post provides a comprehensive, step-by-step guide on integrating an Amazon Bedrock knowledge base with an OpenSearch Service managed cluster as its vector store.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;44
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="e6ae05ad8527eed06b742e47b25bfe4da6bc0d52"
                        open
                      >
                        <summary class="article-expander__title">Monitor agents built on Amazon Bedrock with Datadog LLM Observability</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/monitor-agents-built-on-amazon-bedrock-with-datadog-llm-observability/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/25/ML-18768-dashboard-image-1-1121x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>We’re excited to announce a new integration between Datadog LLM Observability and Amazon Bedrock Agents that helps monitor agentic applications built on Amazon Bedrock. In this post, we&#x27;ll explore how Datadog&#x27;s LLM Observability provides the visibility and control needed to successfully monitor, operate, and debug production-grade agentic applications built on Amazon Bedrock Agents.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;29
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="523e5858fabf4ce89ec4627fa3b28a42f8cca264"
                        open
                      >
                        <summary class="article-expander__title">How PayU built a secure enterprise AI assistant using Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-payu-built-a-secure-enterprise-ai-assistant-using-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/08/ml-19011-solution_architecture-1260x550.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>PayU offers a full-stack digital financial services system that serves the financial needs of merchants, banks, and consumers through technology. In this post, we explain how we equipped the PayU team with an enterprise AI solution and democratized AI access using Amazon Bedrock, without compromising on data residency requirements.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;32
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="3d0a20fa2c3c4c07c5c98f80a4a340ad19cf610c"
                        open
                      >
                        <summary class="article-expander__title">Supercharge generative AI workflows with NVIDIA DGX Cloud on AWS and Amazon Bedrock Custom Model Import</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/supercharge-generative-ai-workflows-with-nvidia-dgx-cloud-on-aws-and-amazon-bedrock-custom-model-import/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/15/ML-18626_FeaturedImg.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post is co-written with Andrew Liu, Chelsea Isaac, Zoey Zhang, and Charlie Huang from NVIDIA. DGX Cloud on Amazon Web Services (AWS) represents a significant leap forward in democratizing access to high-performance AI infrastructure. By combining NVIDIA GPU expertise with AWS scalable cloud services, organizations can accelerate their time-to-train, reduce operational complexity, and unlock […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;32
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="01da8a0ec4b3aaf5618fbf68941d110dcaba2bca"
                        open
                      >
                        <summary class="article-expander__title">Accelerate generative AI inference with NVIDIA Dynamo and Amazon EKS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accelerate-generative-ai-inference-with-nvidia-dynamo-and-amazon-eks/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/15/ML-18555_FeaturedImg.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post introduces NVIDIA Dynamo and explains how to set it up on Amazon EKS for automated scaling and streamlined Kubernetes operations. We provide a hands-on walkthrough, which uses the NVIDIA Dynamo blueprint on the AI on EKS GitHub repo by AWS Labs to provision the infrastructure, configure monitoring, and install the NVIDIA Dynamo operator.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;35
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="7e00991968147a07b0896e1d0057379b055c04f5"
                        open
                      >
                        <summary class="article-expander__title">AWS doubles investment in AWS Generative AI Innovation Center, marking two years of customer success</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/aws-doubles-investment-in-aws-generative-ai-innovation-center-marking-two-years-of-customer-success/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/14/FINAL-BLOG-AND-SOCIAL-MEDIA-IMAGE.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, AWS announces a $100 million additional investment in its AWS Generative AI Innovation Center, marking two years of successful customer collaborations across industries from financial services to healthcare. The investment comes as AI evolves toward more autonomous, agentic systems, with the center already helping thousands of customers drive millions in productivity gains and transform customer experiences.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;30
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-14 datetime="2025-07-14T16:58:48.000Z">2025-07-14</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-14 datetime="2025-07-14T16:58:48.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="c9f7847328e43d6dfac5c640da029cec0393b0c2"
                        open
                      >
                        <summary class="article-expander__title">Build AI-driven policy creation for vehicle data collection and automation using Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-ai-driven-policy-creation-for-vehicle-data-collection-and-automation-using-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/18/image-1-1-1236x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Sonatus partnered with the AWS Generative AI Innovation Center to develop a natural language interface to generate data collection and automation policies using generative AI. This innovation aims to reduce the policy generation process from days to minutes while making it accessible to both engineers and non-experts alike. In this post, we explore how we built this system using Sonatus’s Collector AI and Amazon Bedrock. We discuss the background, challenges, and high-level solution architecture.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="334b2a45e4e77b83fd6ca5da8ce93b59b702530a"
                        open
                      >
                        <summary class="article-expander__title">How Rapid7 automates vulnerability risk scores with ML pipelines using Amazon SageMaker AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-rapid7-automates-vulnerability-risk-scores-with-ml-pipelines-using-amazon-sagemaker-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/24/ML-18959-solution-993x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we share how Rapid7 implemented end-to-end automation for the training, validation, and deployment of ML models that predict CVSS vectors. Rapid7 customers have the information they need to accurately understand their risk and prioritize remediation measures.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="0a280dbba53337526a382e2c10386c1b5133aec3"
                        open
                      >
                        <summary class="article-expander__title">Build secure RAG applications with AWS serverless data lakes</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-secure-rag-applications-with-aws-serverless-data-lakes/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/09/ML-18563_featured.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how to build a secure RAG application using serverless data lake architecture, an important data strategy to support generative AI development. We use Amazon Web Services (AWS) services including Amazon S3, Amazon DynamoDB, AWS Lambda, and Amazon Bedrock Knowledge Bases to create a comprehensive solution supporting unstructured data assets which can be extended to structured data. The post covers how to implement fine-grained access controls for your enterprise data and design metadata-driven retrieval systems that respect security boundaries. These approaches will help you maximize the value of your organization&#x27;s data while maintaining robust security and compliance.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;34
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1662"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #485</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-485/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com YOUR AD COULD BE HERE! SRE Weekly has openings for new sponsorships. Reply or email lex at sreweekly.com for details. Migrating the Jira Database Platform to AWS Aurora How would you migrate several million databases, with minimal impact to your users? Atlassian allocates one Postgres database per tenant customer, with a few […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-11 datetime="2025-07-11T17:26:08.000Z">2025-07-11</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-11 datetime="2025-07-11T17:26:08.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5276be178de4105b7347e6db4e39215a125556b9"
                        open
                      >
                        <summary class="article-expander__title">Advanced fine-tuning methods on Amazon SageMaker AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/advanced-fine-tuning-methods-on-amazon-sagemaker-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/11/advancedfinetuning.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>When fine-tuning ML models on AWS, you can choose the right tool for your specific needs. AWS provides a comprehensive suite of tools for data scientists, ML engineers, and business users to achieve their ML goals. AWS has built solutions to support various levels of ML sophistication, from simple SageMaker training jobs for FM fine-tuning to the power of SageMaker HyperPod for cutting-edge research. We invite you to explore these options, starting with what suits your current needs, and evolve your approach as those needs change.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;35
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="1d3eb57fbeff508effb51cbf963f19b99f9061b2"
                        open
                      >
                        <summary class="article-expander__title">Streamline machine learning workflows with SkyPilot on Amazon SageMaker HyperPod</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/streamline-machine-learning-workflows-with-skypilot-on-amazon-sagemaker-hyperpod/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/11/skypilot-sagemaker-hyperpod.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post is co-written with Zhanghao Wu, co-creator of SkyPilot. The rapid advancement of generative AI and foundation models (FMs) has significantly increased computational resource requirements for machine learning (ML) workloads. Modern ML pipelines require efficient systems for distributing workloads across accelerated compute resources, while making sure developer productivity remains high. Organizations need infrastructure solutions […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5c75628151b3d0f87665085a72ae3c2132788427"
                        open
                      >
                        <summary class="article-expander__title">Intelligent document processing at scale with generative AI and Amazon Bedrock Data Automation</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/intelligent-document-processing-at-scale-with-generative-ai-and-amazon-bedrock-data-automation/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/15/diagram-1260x552.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post presents an end-to-end IDP application powered by Amazon Bedrock Data Automation and other AWS services. It provides a reusable AWS infrastructure as code (IaC) that deploys an IDP pipeline and provides an intuitive UI for transforming documents into structured tables at scale. The application only requires the user to provide the input documents (such as contracts or emails) and a list of attributes to be extracted. It then performs IDP with generative AI.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;35
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="bd565f169e6673b6311a260d4dd54b0187e9b0c5"
                        open
                      >
                        <summary class="article-expander__title">Build a conversational data assistant, Part 2 – Embedding generative business intelligence with Amazon Q in QuickSight</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-conversational-data-assistant-part-2-embedding-generative-business-intelligence-with-amazon-q-in-quicksight/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/12/ml-18672-q-window-858x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we dive into how we integrated Amazon Q in QuickSight to transform natural language requests like “Show me how many items were returned in the US over the past 6 months” into meaningful data visualizations. We demonstrate how combining Amazon Bedrock Agents with Amazon Q in QuickSight creates a comprehensive data assistant that delivers both SQL code and visual insights through a single, intuitive conversational interface—democratizing data access across the enterprise.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;34
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="ab1d6edec05f902da93f2636bc0554eaa894731c"
                        open
                      >
                        <summary class="article-expander__title">Build a conversational data assistant, Part 1: Text-to-SQL with Amazon Bedrock Agents</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-conversational-data-assistant-part-1-text-to-sql-with-amazon-bedrock-agents/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/02/ML-18493-arch-diag-1260x504.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we focus on building a Text-to-SQL solution with Amazon Bedrock, a managed service for building generative AI applications. Specifically, we demonstrate the capabilities of Amazon Bedrock Agents. Part 2 explains how we extended the solution to provide business insights using Amazon Q in QuickSight, a business intelligence assistant that answers questions with auto-generated visualizations.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;34
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="aeac506a770ce5d5bad39429a9ec5787b83a5e7c"
                        open
                      >
                        <summary class="article-expander__title">Implement user-level access control for multi-tenant ML platforms on Amazon SageMaker AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/implement-user-level-access-control-for-multi-tenant-ml-platforms-on-amazon-sagemaker-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/11/user-level-access-control-sagemaker-ai.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we discuss permission management strategies, focusing on attribute-based access control (ABAC) patterns that enable granular user access control while minimizing the proliferation of AWS Identity and Access Management (IAM) roles. We also share proven best practices that help organizations maintain security and compliance without sacrificing operational efficiency in their ML workflows.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;34
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="ba040eed256411e99ad55783d401f94e3c6bef16"
                        open
                      >
                        <summary class="article-expander__title">Long-running execution flows now supported in Amazon Bedrock Flows in public preview</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/long-running-execution-flows-now-supported-in-amazon-bedrock-flows-in-public-preview/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/09/ml-18820-7-1072x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>We announce the public preview of long-running execution (asynchronous) flow support within Amazon Bedrock Flows. With Amazon Bedrock Flows, you can link foundation models (FMs), Amazon Bedrock Prompt Management, Amazon Bedrock Agents, Amazon Bedrock Knowledge Bases, Amazon Bedrock Guardrails, and other AWS services together to build and scale predefined generative AI workflows.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5799522b7de633ff608d3edb43bcd828f7798d8e"
                        open
                      >
                        <summary class="article-expander__title">Fraud detection empowered by federated learning with the Flower framework on Amazon SageMaker AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/fraud-detection-empowered-by-federated-learning-with-the-flower-framework-on-amazon-sagemaker-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/11/Picture2-1-1024x388-1.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how SageMaker and federated learning help financial institutions build scalable, privacy-first fraud detection systems.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;29
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="da98147b19903de78458156ef231c616cf7a9b54"
                        open
                      >
                        <summary class="article-expander__title">Building intelligent AI voice agents with Pipecat and Amazon Bedrock – Part 2</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/building-intelligent-ai-voice-agents-with-pipecat-and-amazon-bedrock-part-2/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/02/ML-18946-arch-diag-1090x630.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In Part 1 of this series, you learned how you can use the combination of Amazon Bedrock and Pipecat, an open source framework for voice and multimodal conversational AI agents to build applications with human-like conversational AI. You learned about common use cases of voice agents and the cascaded models approach, where you orchestrate several components to build your voice AI agent. In this post (Part 2), you explore how to use speech-to-speech foundation model, Amazon Nova Sonic, and the benefits of using a unified model.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;29
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="02936b6af2b2fd66e927f2933428c0db9b4a9583"
                        open
                      >
                        <summary class="article-expander__title">Uphold ethical standards in fashion using multimodal toxicity detection with Amazon Bedrock Guardrails</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/uphold-ethical-standards-in-fashion-using-multimodal-toxicity-detection-with-amazon-bedrock-guardrails/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/26/ML-18310-1.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In the fashion industry, teams are frequently innovating quickly, often utilizing AI. Sharing content, whether it be through videos, designs, or otherwise, can lead to content moderation challenges. There remains a risk (through intentional or unintentional actions) of inappropriate, offensive, or toxic content being produced and shared. In this post, we cover the use of the multimodal toxicity detection feature of Amazon Bedrock Guardrails to guard against toxic content. Whether you’re an enterprise giant in the fashion industry or an up-and-coming brand, you can use this solution to screen potentially harmful content before it impacts your brand’s reputation and ethical standards. For the purposes of this post, ethical standards refer to toxic, disrespectful, or harmful content and images that could be created by fashion designers.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-10 datetime="2025-07-10T19:08:49.000Z">2025-07-10</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-10 datetime="2025-07-10T19:08:49.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5f3e423e1c02ba6e23b3090b017b6cdf56c0b18d"
                        open
                      >
                        <summary class="article-expander__title">New capabilities in Amazon SageMaker AI continue to transform how organizations develop AI models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/new-capabilities-in-amazon-sagemaker-ai-continue-to-transform-how-organizations-develop-ai-models/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/10/smaitransform.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we share some of the new innovations in SageMaker AI that can accelerate how you build and train AI models. These innovations include new observability capabilities in SageMaker HyperPod, the ability to deploy JumpStart models on HyperPod, remote connections to SageMaker AI from local development environments, and fully managed MLflow 3.0.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;29
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="1800436c2b0e26dc7a537aedb6894cc447563536"
                        open
                      >
                        <summary class="article-expander__title">Accelerate foundation model development with one-click observability in Amazon SageMaker HyperPod</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accelerate-foundation-model-development-with-one-click-observability-in-amazon-sagemaker-hyperpod/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/09/smhp-observability-screenshot4-1159x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>With a one-click installation of the Amazon Elastic Kubernetes Service (Amazon EKS) add-on for SageMaker HyperPod observability, you can consolidate health and performance data from NVIDIA DCGM, instance-level Kubernetes node exporters, Elastic Fabric Adapter (EFA), integrated file systems, Kubernetes APIs, Kueue, and SageMaker HyperPod task operators. In this post, we walk you through installing and using the unified dashboards of the out-of-the-box observability feature in SageMaker HyperPod. We cover the one-click installation from the Amazon SageMaker AI console, navigating the dashboard and metrics it consolidates, and advanced topics such as setting up custom alerts.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;29
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="b4b042a28dcc3e7f10327d14087ef28553a26c50"
                        open
                      >
                        <summary class="article-expander__title">Accelerating generative AI development with fully managed MLflow 3.0 on Amazon SageMaker AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accelerating-generative-ai-development-with-fully-managed-mlflow-3-0-on-amazon-sagemaker-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/10/image-1-1206x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how Amazon SageMaker now offers fully managed support for MLflow 3.0, streamlining AI experimentation and accelerating your generative AI journey from idea to production. This release transforms managed MLflow from experiment tracking to providing end-to-end observability, reducing time-to-market for generative AI development.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="b0e289de407526fc72af2e48d1b22076232878b1"
                        open
                      >
                        <summary class="article-expander__title">Amazon SageMaker HyperPod launches model deployments to accelerate the generative AI model development lifecycle</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-hyperpod-launches-model-deployments-to-accelerate-the-generative-ai-model-development-lifecycle/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/10/image-2-5-1150x630.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we announce Amazon SageMaker HyperPod support for deploying foundation models from SageMaker JumpStart, as well as custom or fine-tuned models from Amazon S3 or Amazon FSx. This new capability allows customers to train, fine-tune, and deploy models on the same HyperPod compute resources, maximizing resource utilization across the entire model lifecycle.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;36
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="36772a3aa633a43455b6531ebc2f0def08d4b8a4"
                        open
                      >
                        <summary class="article-expander__title">Supercharge your AI workflows by connecting to SageMaker Studio from Visual Studio Code</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/supercharge-your-ai-workflows-by-connecting-to-sagemaker-studio-from-visual-studio-code/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/09/ML-19130_FeaturedImg.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>AI developers and machine learning (ML) engineers can now use the capabilities of Amazon SageMaker Studio directly from their local Visual Studio Code (VS Code). With this capability, you can use your customized local VS Code setup, including AI-assisted development tools, custom extensions, and debugging tools while accessing compute resources and your data in SageMaker Studio. In this post, we show you how to remotely connect your local VS Code to SageMaker Studio development environments to use your customized development environment while accessing Amazon SageMaker AI compute resources.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;33
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="4f61bc00f2d7a850e07a235b937507ba4efcf977"
                        open
                      >
                        <summary class="article-expander__title">Use K8sGPT and Amazon Bedrock for simplified Kubernetes cluster maintenance</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/use-k8sgpt-and-amazon-bedrock-for-simplified-kubernetes-cluster-maintenance/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/08/ML-17546-image-5-1-1260x588.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post demonstrates the best practices to run K8sGPT in AWS with Amazon Bedrock in two modes: K8sGPT CLI and K8sGPT Operator. It showcases how the solution can help SREs simplify Kubernetes cluster management through continuous monitoring and operational intelligence.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;34
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="7c4dd64a29aa9690e455ba0508ebde6f74b98ceb"
                        open
                      >
                        <summary class="article-expander__title">How Rocket streamlines the home buying experience with Amazon Bedrock Agents</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-rocket-streamlines-the-home-buying-experience-with-amazon-bedrock-agents/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/03/RocketAgents-759x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Rocket AI Agent is more than a digital assistant. It’s a reimagined approach to client engagement, powered by agentic AI. By combining Amazon Bedrock Agents with Rocket’s proprietary data and backend systems, Rocket has created a smarter, more scalable, and more human experience available 24/7, without the wait. This post explores how Rocket brought that vision to life using Amazon Bedrock Agents, powering a new era of AI-driven support that is consistently available, deeply personalized, and built to take action.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;32
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="688c1438c31620328dbafdc9c9315eb397595f21"
                        open
                      >
                        <summary class="article-expander__title">Build an MCP application with Mistral models on AWS</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-an-mcp-application-with-mistral-models-on-aws/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/30/ML-18862-image-1-1151x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post demonstrates building an intelligent AI assistant using Mistral AI models on AWS and MCP, integrating real-time location services, time data, and contextual memory to handle complex multimodal queries. This use case, restaurant recommendations, serves as an example, but this extensible framework can be adapted for enterprise use cases by modifying MCP server configurations to connect with your specific data sources and business systems.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;37
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="934bba4fd8cf53cd9a63c7cb3d4d072145373d2b"
                        open
                      >
                        <summary class="article-expander__title">Build real-time conversational AI experiences using Amazon Nova Sonic and LiveKit</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-real-time-conversational-ai-experiences-using-amazon-nova-sonic-and-livekit/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/09/ml-19251-943x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>mazon Nova Sonic is now integrated with LiveKit’s WebRTC framework, a widely used platform that enables developers to build real-time audio, video, and data communication applications. This integration makes it possible for developers to build conversational voice interfaces without needing to manage complex audio pipelines or signaling protocols. In this post, we explain how this integration works, how it addresses the historical challenges of voice-first applications, and some initial steps to start using this solution.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;28
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="http://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://blog.thestateofme.com/?p&#x3D;6404"
                        open
                      >
                        <summary class="article-expander__title">Using Architecture Decision Records (ADRs) with AI coding assistants</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://blog.thestateofme.com/2025/07/10/using-architecture-decision-records-adrs-with-ai-coding-assistants/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/07/doug_adrs.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Last week my former colleague Doug Todd asked a question about recording decisions on BlueSky: Of course I replied suggesting Architecture Decision Records (ADRs), with a pointer to the at_protocol GitHub repo where we use them. A few days back Doug demoed how he’s using ADRs with his coding assistant (Claude and Claude Code), and […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6404"
                        open
                      >
                        <summary class="article-expander__title">Using Architecture Decision Records (ADRs) with AI coding assistants</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/07/10/using-architecture-decision-records-adrs-with-ai-coding-assistants/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/07/doug_adrs.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Last week my former colleague Doug Todd asked a question about recording decisions on BlueSky: Of course I replied suggesting Architecture Decision Records (ADRs), with a pointer to the at_protocol GitHub repo where we use them. A few days back Doug demoed how he’s using ADRs with his coding assistant (Claude and Claude Code), and […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-09 datetime="2025-07-09T21:01:52.000Z">2025-07-09</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-09 datetime="2025-07-09T21:01:52.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="0cec86574db04fac7d6af46ff916765a68ee60d0"
                        open
                      >
                        <summary class="article-expander__title">AWS AI infrastructure with NVIDIA Blackwell: Two powerful compute solutions for the next frontier of AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/aws-ai-infrastructure-with-nvidia-blackwell-two-powerful-compute-solutions-for-the-next-frontier-of-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/08/blackwell.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we announce general availability of Amazon EC2 P6e-GB200 UltraServers and P6-B200 instances, powered by NVIDIA Blackwell GPUs, designed for training and deploying the largest, most sophisticated AI models.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;30
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="b6db8e7820203308b2b007f461b2f8712657cb95"
                        open
                      >
                        <summary class="article-expander__title">Unlock retail intelligence by transforming data into actionable insights using generative AI with Amazon Q Business</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/unlock-retail-intelligence-by-transforming-data-into-actionable-insights-using-generative-ai-with-amazon-q-business/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/03/ML-18557image-8-1120x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Amazon Q Business for Retail Intelligence is an AI-powered assistant designed to help retail businesses streamline operations, improve customer service, and enhance decision-making processes. This solution is specifically engineered to be scalable and adaptable to businesses of various sizes, helping them compete more effectively. In this post, we show how you can use Amazon Q Business for Retail Intelligence to transform your data into actionable insights.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;30
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="bf2de285d2a43781c9492fae032a4837decb72b0"
                        open
                      >
                        <summary class="article-expander__title">Democratize data for timely decisions with text-to-SQL at Parcel Perform</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/democratize-data-for-timely-decisions-with-text-to-sql-at-parcel-perform/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/02/ML-18476-ai-assistant-screenshot-862x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>The business team in Parcel Perform often needs access to data to answer questions related to merchants’ parcel deliveries, such as “Did we see a spike in delivery delays last week? If so, in which transit facilities were this observed, and what was the primary cause of the issue?” Previously, the data team had to manually form the query and run it to fetch the data. With the new generative AI-powered text-to-SQL capability in Parcel Perform, the business team can self-serve their data needs by using an AI assistant interface. In this post, we discuss how Parcel Perform incorporated generative AI, data storage, and data access through AWS services to make timely decisions.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;34
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="08277c106aba67e0a240570ab9cbd2c2fc846002"
                        open
                      >
                        <summary class="article-expander__title">Query Amazon Aurora PostgreSQL using Amazon Bedrock Knowledge Bases structured data</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/query-amazon-aurora-postgresql-using-amazon-bedrock-knowledge-bases-structured-data/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/26/ML-18260-arch-diagram-1260x511.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we discuss how to make your Amazon Aurora PostgreSQL-Compatible Edition data available for natural language querying through Amazon Bedrock Knowledge Bases while maintaining data freshness.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="0ca630f1267ff81978a0437eb3354815207ec08b"
                        open
                      >
                        <summary class="article-expander__title">Configure fine-grained access to Amazon Bedrock models using Amazon SageMaker Unified Studio</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/configure-fine-grained-access-to-amazon-bedrock-models-using-amazon-sagemaker-unified-studio/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/26/image-1-29.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to use SageMaker Unified Studio and AWS Identity and Access Management (IAM) to establish a robust permission framework for Amazon Bedrock models. We show how administrators can precisely manage which users and teams have access to specific models within a secure, collaborative environment. We guide you through creating granular permissions to control model access, with code examples for common enterprise governance scenarios.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;35
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="0ea795ad0403b7e919108b10ecaaf02e91e29e62"
                        open
                      >
                        <summary class="article-expander__title">Improve conversational AI response times for enterprise applications with the Amazon Bedrock streaming API and AWS AppSync</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/improve-conversational-ai-response-times-for-enterprise-applications-with-the-amazon-bedrock-streaming-api-and-aws-appsync/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/24/ML-15925-image-1-977x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post demonstrates how integrating an Amazon Bedrock streaming API with AWS AppSync subscriptions significantly enhances AI assistant responsiveness and user satisfaction. By implementing this streaming approach, the global financial services organization reduced initial response times for complex queries by approximately 75%—from 10 seconds to just 2–3 seconds—empowering users to view responses as they’re generated rather than waiting for complete answers.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;30
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="27f2aaffc688afc9cd9002c84690dde765cf7de5"
                        open
                      >
                        <summary class="article-expander__title">Scale generative AI use cases, Part 1: Multi-tenant hub and spoke architecture using AWS Transit Gateway</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/scale-generative-ai-use-cases-part-1-multi-tenant-hub-and-spoke-architecture-using-aws-transit-gateway/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/01/ML-16510-architecture-daigram-1009x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>n this two-part series, we discuss a hub and spoke architecture pattern for building a multi-tenant and multi-account architecture. This pattern supports abstractions for shared services across use cases and teams, helping create secure, scalable, and reliable generative AI systems. In Part 1, we present a centralized hub for generative AI service abstractions and tenant-specific spokes, using AWS Transit Gateway for cross-account interoperability.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;32
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-08 datetime="2025-07-08T20:04:11.000Z">2025-07-08</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-08 datetime="2025-07-08T20:04:11.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="a3096eda573d985bf00a40d051bfa466b0637e1b"
                        open
                      >
                        <summary class="article-expander__title">Accelerate AI development with Amazon Bedrock API keys</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accelerate-ai-development-with-amazon-bedrock-api-keys/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/08/apikeys.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Today, we’re excited to announce a significant improvement to the developer experience of Amazon Bedrock: API keys. API keys provide quick access to the Amazon Bedrock APIs, streamlining the authentication process so that developers can focus on building rather than configuration.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;28
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="f35c9887d208a5fb54c9897d9ef301096e3fa89a"
                        open
                      >
                        <summary class="article-expander__title">Accelerating data science innovation: How Bayer Crop Science used AWS AI/ML services to build their next-generation MLOps service</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accelerating-data-science-innovation-how-bayer-crop-science-used-aws-ai-ml-services-to-build-their-next-generation-mlops-service/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/04/Agriculture-stock-image-1119x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show how Bayer Crop Science manages large-scale data science operations by training models for their data analytics needs and maintaining high-quality code documentation to support developers. Through these solutions, Bayer Crop Science projects up to a 70% reduction in developer onboarding time and up to a 30% improvement in developer productivity.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;30
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="dd783068e048915082ca0b93b2eac8371a1c4997"
                        open
                      >
                        <summary class="article-expander__title">Combat financial fraud with GraphRAG on Amazon Bedrock Knowledge Bases</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/combat-financial-fraud-with-graphrag-on-amazon-bedrock-knowledge-bases/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/01/ML-18896-image-7-1260x562.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show how to use Amazon Bedrock Knowledge Bases GraphRAG with Amazon Neptune Analytics to build a financial fraud detection solution.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="f0af6bb14e0ac1b756d9cd479511f78ab75691ec"
                        open
                      >
                        <summary class="article-expander__title">Classify call center conversations with Amazon Bedrock batch inference</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/classify-call-center-conversations-with-amazon-bedrock-batch-inference/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/27/excel_sample-1246x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to build an end-to-end solution for text classification using the Amazon Bedrock batch inference capability with the Anthropic’s Claude Haiku model. We walk through classifying travel agency call center conversations into categories, showcasing how to generate synthetic training data, process large volumes of text data, and automate the entire workflow using AWS services.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;34
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="942711a2fd84cc038e5b1f9152a733fd2f493ceb"
                        open
                      >
                        <summary class="article-expander__title">Effective cross-lingual LLM evaluation with Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/effective-cross-lingual-llm-evaluation-with-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/25/ml-18669-human-eval-1-1229x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to use the evaluation features of Amazon Bedrock to deliver reliable results across language barriers without the need for localized prompts or custom infrastructure. Through comprehensive testing and analysis, we share practical strategies to help reduce the cost and complexity of multilingual evaluation while maintaining high standards across global large language model (LLM) deployments.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;33
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="157186e6af7d5b5f5741b85e5d87cfecfb7f732b"
                        open
                      >
                        <summary class="article-expander__title">Cohere Embed 4 multimodal embeddings model is now available on Amazon SageMaker JumpStart</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/cohere-embed-4-multimodal-embeddings-model-is-now-available-on-amazon-sagemaker-jumpstart/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/02/ML-18864-image-1-1039x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>The Cohere Embed 4 multimodal embeddings model is now generally available on Amazon SageMaker JumpStart. The Embed 4 model is built for multimodal business documents, has leading multilingual capabilities, and offers notable improvement over Embed 3 across key benchmarks. In this post, we discuss the benefits and capabilities of this new model. We also walk you through how to deploy and use the Embed 4 model using SageMaker JumpStart.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-07 datetime="2025-07-07T20:40:49.000Z">2025-07-07</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-07 datetime="2025-07-07T20:40:49.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="161c14f09381ba8e40c4329e7d164533be3eac36"
                        open
                      >
                        <summary class="article-expander__title">How INRIX accelerates transportation planning with Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-inrix-accelerates-transportation-planning-with-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/24/image-ML-18195-3-1120x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>INRIX pioneered the use of GPS data from connected vehicles for transportation intelligence. In this post, we partnered with Amazon Web Services (AWS) customer INRIX to demonstrate how Amazon Bedrock can be used to determine the best countermeasures for specific city locations using rich transportation data and how such countermeasures can be automatically visualized in street view images. This approach allows for significant planning acceleration compared to traditional approaches using conceptual drawings.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;30
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="0f4b683fa29b2a45811f7aad59b14d2a9166c977"
                        open
                      >
                        <summary class="article-expander__title">Qwen3 family of reasoning models now available in Amazon Bedrock Marketplace and Amazon SageMaker JumpStart</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/qwen3-family-of-reasoning-models-now-available-in-amazon-bedrock-marketplace-and-amazon-sagemaker-jumpstart/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/03/Screenshot-2025-07-03-at-1.48.42 PM-1119x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Today, we are excited to announce that Qwen3, the latest generation of large language models (LLMs) in the Qwen family, is available through Amazon Bedrock Marketplace and Amazon SageMaker JumpStart. With this launch, you can deploy the Qwen3 models—available in 0.6B, 4B, 8B, and 32B parameter sizes—to build, experiment, and responsibly scale your generative AI applications on AWS. In this post, we demonstrate how to get started with Qwen3 on Amazon Bedrock Marketplace and SageMaker JumpStart.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;34
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="1e51c0703ef73b084f5093101bc0ea6620924e8e"
                        open
                      >
                        <summary class="article-expander__title">Build a just-in-time knowledge base with Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-a-just-in-time-knowledge-base-with-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/18/ML-18649-architecture-697x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Traditional Retrieval Augmented Generation (RAG) systems consume valuable resources by ingesting and maintaining embeddings for documents that might never be queried, resulting in unnecessary storage costs and reduced system efficiency. This post presents a just-in-time knowledge base solution that reduces unused consumption through intelligent document processing. The solution processes documents only when needed and automatically removes unused resources, so organizations can scale their document repositories without proportionally increasing infrastructure costs.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="30c156798ccfba185ff4d7bf60bfc7c24f2bc9bf"
                        open
                      >
                        <summary class="article-expander__title">Agents as escalators: Real-time AI video monitoring with Amazon Bedrock Agents and video streams</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/agents-as-escalators-real-time-ai-video-monitoring-with-amazon-bedrock-agents-and-video-streams/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/12/image-3-12-798x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show how to build a fully deployable solution that processes video streams using OpenCV, Amazon Bedrock for contextual scene understanding and automated responses through Amazon Bedrock Agents. This solution extends the capabilities demonstrated in Automate chatbot for document and data retrieval using Amazon Bedrock Agents and Knowledge Bases, which discussed using Amazon Bedrock Agents for document and data retrieval. In this post, we apply Amazon Bedrock Agents to real-time video analysis and event monitoring.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;37
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1660"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #484</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-484/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com Exact Code Search: Find code faster across repositories This is really neat! They’ve developed a new approach to search that uses 3-letter “trigrams” rather than tokenizing words, making it especially well-suited to code search. It converts regular expressions to trigram searches behind the scenes.   Dmitry Gruzd — GitLab Pattern machines that we […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-05 datetime="2025-07-05T00:00:00.000Z">2025-07-05</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-05 datetime="2025-07-05T00:00:00.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Toby Liu</button>
                  <a class="source-heading__link" href="https://liuning0820.github.io/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://liuning0820.github.io/2025/07/05/public-ollama-models.html"
                        open
                      >
                        <summary class="article-expander__title">Public Ollama Models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://liuning0820.github.io/2025/07/05/public-ollama-models.html">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Public Ollama Models 2025-07-05 How to chat with Ollama models Select an IP and model from the table below, then use them in this command: # Start a conversation with a model # Replace &lt;IP&gt; with an IP from the table below # Replace &lt;MODEL&gt; with one of the models listed for that IP curl -X POST http://&lt;IP&gt;:11434/api/chat -d &#x27;{ &quot;model&quot;: &quot;&lt;MODEL&gt;&quot;, &quot;messages&quot;: [{ &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello, how are you?&quot; }] }&#x27; Available Models IP Models 222.70.88.44 qwen3:8bdeepseek-r1:8bdeepseek-r1:7bqwen3:30b-a3bnomic-embed-text:latestbge-m3:latest 117.50.179.196 smollm2:135mhf.co/IlyaGusev/saiga_nemo_12b_gguf:Q5_K_M 117.50.197.100 qwen2.5:7bbge-m3:567mqwen2.5vl:7b 117.50.164.136 qwen3:1.7bnomic-embed-text:v1.5qwen3:4bllama3.2:3b-instruct-q5_K_M 106.14.202.11 mxbai-embed-large:latest 163.228.156.198 qwen3:8b-nothinkqwen3:8bdeepseek-r1:8bqwen2.5:32bqwen2.5-coder:7bQwen2.5-7B-Instruct-Distill-ds-r1-110k:latestQwen2.5-7B-Instruct:7bQwen2.5-7B-Distill-ds-r1-110k:7bqwq:latestsmollm2:135mqwen2.5:3B-Traineddeepseek-r1:32bdeepseek-r1:14bllava:latestnomic-embed-text:latestqwen2.5:latestdeepseek-r1:7b 218.1.151.175 smollm2:135mnomic-embed-text:latestqwen2.5:latest 218.78.108.171 deepseek-r1:14bdeepseek-r1:7bdeepseek-r1:1.5b 117.50.245.70 smollm2:135mqwen2.5:32bqwen2.5:7bgemma2:27bgemma2:2bqwen2.5:14bdeepseek-r1:14bdeepseek-r1:7bgemma3:4bnomic-embed-text:latestdeepseek-r1:1.5bgemma3:12bgemma3:27bqwen2.5-coder:latestunsloth.F16.gguf:latestunsloth.Q8_0.gguf:latest 117.50.194.3 dengcao/Qwen3-Embedding-8B:Q5_K_Mdengcao/Qwen3-Embedding-4B:Q5_K_M 61.165.183.106 huihui_ai/deepseek-r1-abliterated:70b-llama-distill-q8_0 124.71.154.35 llama3.2:3b-instruct-q5_K_Mdeepseek-r1:1.5bnomic-embed-text:latest 117.50.174.178 smollm2:135mqwen2.5:7bdeepseek-r1:8b 117.50.175.121 changji_medical_deepseek_r1:14bchangji_medical_deepseek_r1:32b 101.132.102.117 smollm2:135mbge-m3:567mdeepseek-r1:1.5b 117.50.250.245 qwen3:8b_nothinkqwen3:8b 143.64.160.92 llama3.2:3b-instruct-q5_K_MMartinRizzo/Ayla-Light-v2:12b-q4_K_M 58.246.1.174 llama3.2:3b-instruct-q5_K_Mqwen2.5:32b 61.172.167.153 deepseek-r1:7b 61.172.167.211 deepseek-r1:7b 61.169.115.204 nomic-embed-text:latestdeepseek-r1:32b 47.116.202.9 qwen3-no-think:latestqwen3:latestqwen3:8bqwen:7bllava:latestmistral:7b-instructnomic-embed-text:latestqllama/bge-reranker-v2-m3:latestbge-large:latestdeepseek-r1:7bbge-m3:latestdeepseek-r1:latestdeepseek-r1:1.5bqwen2:latest 223.166.95.229 deepseek-r1:7bdeepseek-r1:14bdeepseek-r1:8bqwen3:latestqwen3:14bqwen2.5vl:32bqwen2.5vl:latestqwen3:8bgemma3:12bgemma3:27bllava:34bllava:13bmxbai-embed-large:latestnomic-embed-text:latestqwq:latestcodellama:13bllama3.2-vision:latestqwen2.5-coder:latestqwen2.5-coder:14bphi4:latestphi3:14bmistral:latestllama3.3:latestllama3.2:latestllama3.1:latestllama3:latestllama3:70bgemma2:latestgemma2:27b 180.158.174.61 qwq:32b-q8_0qwq:32b-16384contextqwq:32bnomic-embed-text:latestdeepseek-r1:32bdeepseek-r1:14bllama3.2-vision:11bqwen2.5:32bllama3.2:latest Disclaimer These Ollama model endpoints are publicly exposed interfaces found on the internet. They are listed here for informational purposes only. Please be aware that: These endpoints are not maintained or controlled by us The availability and stability of these services cannot be guaranteed Use these services at your own risk We take no responsibility for any issues or damages that may arise from using these endpoints 免责声明 本文列出的 Ollama 模型接口均来自互联网上公开暴露的端点。请注意： 这些端点并非由我们维护或控制 无法保证这些服务的可用性和稳定性 使用这些服务需自行承担风险 对于使用这些端点可能产生的任何问题或损失，我们不承担任何责任</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-03 datetime="2025-07-03T14:07:44.000Z">2025-07-03</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-03 datetime="2025-07-03T14:07:44.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="bc7ad85bd9531c15d4c83702542cf8b4169bd458"
                        open
                      >
                        <summary class="article-expander__title">Transforming network operations with AI: How Swisscom built a network assistant using Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/transforming-network-operations-with-ai-how-swisscom-built-a-network-assistant-using-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/03/feature-image-ML-18876-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how Swisscom developed their Network Assistant. We discuss the initial challenges and how they implemented a solution that delivers measurable benefits. We examine the technical architecture, discuss key learnings, and look at future enhancements that can further transform network operations.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;32
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="80109ceea3e3b1433b767eac2fb6eb7e8f32ca7c"
                        open
                      >
                        <summary class="article-expander__title">End-to-End model training and deployment with Amazon SageMaker Unified Studio</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/end-to-end-model-training-and-deployment-with-amazon-sagemaker-unified-studio/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/03/feature-image-ML-18967-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we guide you through the stages of customizing large language models (LLMs) with SageMaker Unified Studio and SageMaker AI, covering the end-to-end process starting from data discovery to fine-tuning FMs with SageMaker AI distributed training, tracking metrics using MLflow, and then deploying models using SageMaker AI inference for real-time inference. We also discuss best practices to choose the right instance size and share some debugging best practices while working with JupyterLab notebooks in SageMaker Unified Studio.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;37
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-02 datetime="2025-07-02T20:55:51.000Z">2025-07-02</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-02 datetime="2025-07-02T20:55:51.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="28b941e13e36b3fdad12789a9bef8df1ff2f4587"
                        open
                      >
                        <summary class="article-expander__title">Optimize RAG in production environments using Amazon SageMaker JumpStart and Amazon OpenSearch Service</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/optimize-rag-in-production-environments-using-amazon-sagemaker-jumpstart-and-amazon-opensearch-service/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/02/feature-image-ML-18052-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we show how to use Amazon OpenSearch Service as a vector store to build an efficient RAG application.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;34
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="97fd357f8f6ce597a772d1ed354bff38e0a1b55e"
                        open
                      >
                        <summary class="article-expander__title">Advancing AI agent governance with Boomi and AWS: A unified approach to observability and compliance</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/advancing-ai-agent-governance-with-boomi-and-aws-a-unified-approach-to-observability-and-compliance/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/02/feature-image-ML-18721-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we share how Boomi partnered with AWS to help enterprises accelerate and scale AI adoption with confidence using Agent Control Tower.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;28
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-07-01 datetime="2025-07-01T20:42:28.000Z">2025-07-01</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-07-01 datetime="2025-07-01T20:42:28.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="eb0f20964bd26115c04513adc2abea973e55a43d"
                        open
                      >
                        <summary class="article-expander__title">Use Amazon SageMaker Unified Studio to build complex AI workflows using Amazon Bedrock Flows</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/use-amazon-sagemaker-unified-studio-to-build-complex-ai-workflows-using-amazon-bedrock-flows/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/01/feature-image-ML-18869-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how you can use SageMaker Unified Studio to create complex AI workflows using Amazon Bedrock Flows.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;31
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5e3957ba5c8e1a3b6664196b58b9b27f1912932b"
                        open
                      >
                        <summary class="article-expander__title">Accelerating AI innovation: Scale MCP servers for enterprise workloads with Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/accelerating-ai-innovation-scale-mcp-servers-for-enterprise-workloads-with-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/01/scalemcp.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we present a centralized Model Context Protocol (MCP) server implementation using Amazon Bedrock that provides shared access to tools and resources for enterprise AI workloads. The solution enables organizations to accelerate AI innovation by standardizing access to resources and tools through MCP, while maintaining security and governance through a centralized approach.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;32
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="5bd9302e7478c4c1145f061ec277d3d079c8f670"
                        open
                      >
                        <summary class="article-expander__title">Choosing the right approach for generative AI-powered structured data retrieval</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/choosing-the-right-approach-for-generative-ai-powered-structured-data-retrieval/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/17/image-7-6-1140x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore five different patterns for implementing LLM-powered structured data query capabilities in AWS, including direct conversational interfaces, BI tool enhancements, and custom text-to-SQL solutions.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;32
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="3e020a2fcdee7aaf4e069ad5230003683ba56c48"
                        open
                      >
                        <summary class="article-expander__title">Revolutionizing drug data analysis using Amazon Bedrock multimodal RAG capabilities</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/revolutionizing-drug-data-analysis-using-amazon-bedrock-multimodal-rag-capabilities/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/07/01/drugdataanalysis.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how Amazon Bedrock&#x27;s multimodal RAG capabilities revolutionize drug data analysis by efficiently processing complex medical documentation containing text, images, graphs, and tables.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;32
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Chris Swan&#x27;s Weblog</button>
                  <a class="source-heading__link" href="http://blog.thestateofme.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://blog.thestateofme.com/?p&#x3D;6399"
                        open
                      >
                        <summary class="article-expander__title">Milo cancer diary part 20 – extended remission</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://blog.thestateofme.com/2025/07/01/milo-cancer-diary-part-20-extended-remission/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/07/milo_raspberries.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Milo was back at North Downs Specialist Referrals today for his second scan since finishing his third (modified) ‘CHOP’ chemotherapy protocol. Amazingly he’s still looking clear, which means this is now the longest period of remission since he started treatment :) Our fingers will be crossed for the next scan in a couple of months […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6399"
                        open
                      >
                        <summary class="article-expander__title">Milo cancer diary part 20 – extended remission</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/07/01/milo-cancer-diary-part-20-extended-remission/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/07/milo_raspberries.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Milo was back at North Downs Specialist Referrals today for his second scan since finishing his third (modified) ‘CHOP’ chemotherapy protocol. Amazingly he’s still looking clear, which means this is now the longest period of remission since he started treatment :) Our fingers will be crossed for the next scan in a couple of months […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://blog.thestateofme.com/?p&#x3D;6315"
                        open
                      >
                        <summary class="article-expander__title">June 2025</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://blog.thestateofme.com/2025/07/01/june-2025/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/06/pups_202506.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Pupdate There’s been a bumper crop of raspberries this year, which has kept the boys entertained.. Berlin Google’s I/O Connect event was in Berlin once again, which provided a good chance to catch up with various communities and some of the product folk. I also took the chance to grab dinner with some local ex-pat […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://blog.thestateofme.com/?p&#x3D;6315"
                        open
                      >
                        <summary class="article-expander__title">June 2025</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://blog.thestateofme.com/2025/07/01/june-2025/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blog.thestateofme.com/wp-content/uploads/2025/06/pups_202506.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Pupdate There’s been a bumper crop of raspberries this year, which has kept the boys entertained.. Berlin Google’s I/O Connect event was in Berlin once again, which provided a good chance to catch up with various communities and some of the product folk. I also took the chance to grab dinner with some local ex-pat […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-30 datetime="2025-06-30T21:51:09.000Z">2025-06-30</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-30 datetime="2025-06-30T21:51:09.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="67a012ba777215649f71386fff3cf1a5dcf07df3"
                        open
                      >
                        <summary class="article-expander__title">Build and deploy AI inference workflows with new enhancements to the Amazon SageMaker Python SDK</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-and-deploy-ai-inference-workflows-with-new-enhancements-to-the-amazon-sagemaker-python-sdk/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/02/featured-images-ML-17750-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we provide an overview of the user experience, detailing how to set up and deploy these workflows with multiple models using the SageMaker Python SDK. We walk through examples of building complex inference workflows, deploying them to SageMaker endpoints, and invoking them for real-time inference.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;35
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="45c47e5ef40dc0084bb4208c06e2a04a8df0be0b"
                        open
                      >
                        <summary class="article-expander__title">Context extraction from image files in Amazon Q Business using LLMs</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/context-extraction-from-image-files-in-amazon-q-business-using-llms/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/30/contextextraction.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we look at a step-by-step implementation for using the custom document enrichment (CDE) feature within an Amazon Q Business application to process standalone image files. We walk you through an AWS Lambda function configured within CDE to process various image file types, and showcase an example scenario of how this integration enhances Amazon Q Business&#x27;s ability to provide comprehensive insights.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;100
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="7a26d1e283e9cd00b8df531415b7adfb8ed4f799"
                        open
                      >
                        <summary class="article-expander__title">Build AWS architecture diagrams using Amazon Q CLI and MCP</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-aws-architecture-diagrams-using-amazon-q-cli-and-mcp/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/30/qclimcparchdiag.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how to use Amazon Q Developer CLI with the AWS Diagram MCP and the AWS Documentation MCP servers to create sophisticated architecture diagrams that follow AWS best practices. We discuss techniques for basic diagrams and real-world diagrams, with detailed examples and step-by-step instructions.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;98
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1658"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #483</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-483/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com A message from our sponsor, PagerDuty: When the internet faltered on June 12th, other incident management platforms may have crashed—but PagerDuty handled a 172% surge in incidents and 433% spike in notifications flawlessly. Your platform should be rock-solid during a storm, not another worry. See what sets PagerDuty’s reliability apart. The same […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-27 datetime="2025-06-27T16:34:01.000Z">2025-06-27</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-27 datetime="2025-06-27T16:34:01.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="cd8136b2c81b2175a22483ec1cc2688eab673c13"
                        open
                      >
                        <summary class="article-expander__title">AWS costs estimation using Amazon Q CLI and AWS Cost Analysis MCP</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/aws-costs-estimation-using-amazon-q-cli-and-aws-cost-analysis-mcp/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/27/costmcp.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we explore how to use Amazon Q CLI with the AWS Cost Analysis MCP server to perform sophisticated cost analysis that follows AWS best practices. We discuss basic setup and advanced techniques, with detailed examples and step-by-step instructions.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;98
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-26 datetime="2025-06-26T22:41:26.000Z">2025-06-26</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-26 datetime="2025-06-26T22:41:26.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="393f2e315f5a320bd5bf91e9f752f2412d11285e"
                        open
                      >
                        <summary class="article-expander__title">Tailor responsible AI with new safeguard tiers in Amazon Bedrock Guardrails</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/tailor-responsible-ai-with-new-safeguard-tiers-in-amazon-bedrock-guardrails/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/26/feature-image-ML-19081-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we introduce the new safeguard tiers available in Amazon Bedrock Guardrails, explain their benefits and use cases, and provide guidance on how to implement and evaluate them in your AI applications.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;98
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6b9ffd16ee65772d5702156adb102bea755928bd"
                        open
                      >
                        <summary class="article-expander__title">Structured data response with Amazon Bedrock: Prompt Engineering and Tool Use</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/structured-data-response-with-amazon-bedrock-prompt-engineering-and-tool-use/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/12/ML-17009-image-8-1153x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>We demonstrate two methods for generating structured responses with Amazon Bedrock: Prompt Engineering and Tool Use with the Converse API. Prompt Engineering is flexible, works with Bedrock models (including those without Tool Use support), and handles various schema types (e.g., Open API schemas), making it a great starting point. Tool Use offers greater reliability, consistent results, seamless API integration, and runtime validation of JSON schema for enhanced control.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;95
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="692e307da12573bce51c0f803dcfc6bbb1c2fa31"
                        open
                      >
                        <summary class="article-expander__title">Using Amazon SageMaker AI Random Cut Forest for NASA’s Blue Origin spacecraft sensor data</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/using-amazon-sagemaker-ai-random-cut-forest-for-nasas-blue-origin-spacecraft-sensor-data/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/20/ML-18124-velocities-1136x630.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to use SageMaker AI to apply the Random Cut Forest (RCF) algorithm to detect anomalies in spacecraft position, velocity, and quaternion orientation data from NASA and Blue Origin’s demonstration of lunar Deorbit, Descent, and Landing Sensors (BODDL-TP).</span>
                                &ensp;<span class="article-reading-time">(&hairsp;99
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-25 datetime="2025-06-25T16:53:54.000Z">2025-06-25</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-25 datetime="2025-06-25T16:53:54.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="ef536dd9c44d93fccd7861b178211a4a5642578c"
                        open
                      >
                        <summary class="article-expander__title">Build an intelligent multi-agent business expert using Amazon Bedrock</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-an-intelligent-multi-agent-business-expert-using-amazon-bedrock/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/05/image-2-8-876x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how to build a multi-agent system using multi-agent collaboration in Amazon Bedrock Agents to solve complex business questions in the biopharmaceutical industry. We show how specialized agents in research and development (R&amp;D), legal, and finance domains can work together to provide comprehensive business insights by analyzing data from multiple sources.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;100
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="dc5782f5c440ee1a67b72c8b98d7cdc484f72b01"
                        open
                      >
                        <summary class="article-expander__title">Driving cost-efficiency and speed in claims data processing with Amazon Nova Micro and Amazon Nova Lite</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/driving-cost-efficiency-and-speed-in-claims-data-processing-with-amazon-nova-micro-and-amazon-nova-lite/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/10/ML-18438-arch.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we shared how an internal technology team at Amazon evaluated Amazon Nova models, resulting in notable improvements in inference speed and cost-efficiency.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-24 datetime="2025-06-24T23:44:24.000Z">2025-06-24</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-24 datetime="2025-06-24T23:44:24.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="e6696f91fc2548786df67293ddde369a85a496a8"
                        open
                      >
                        <summary class="article-expander__title">Power Your LLM Training and Evaluation with the New SageMaker AI Generative AI Tools</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/power-your-llm-training-and-evaluation-with-the-new-sagemaker-ai-generative-ai-tools/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/24/feature-image-ML-17584-1120x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Today we are excited to introduce the Text Ranking and Question and Answer UI templates to SageMaker AI customers. In this blog post, we’ll walk you through how to set up these templates in SageMaker to create high-quality datasets for training your large language models.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;95
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="e1237a68f02382bc65316d4a7963871a3dc4be4b"
                        open
                      >
                        <summary class="article-expander__title">Amazon Bedrock Agents observability using Arize AI</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-agents-observability-using-arize-ai/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/23/ML-18823-image-1-1260x570.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Today, we’re excited to announce a new integration between Arize AI and Amazon Bedrock Agents that addresses one of the most significant challenges in AI development: observability. In this post, we demonstrate the Arize Phoenix system for tracing and evaluation.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;100
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="a9a5151f861b5e561019bd8cde0ac61c60774255"
                        open
                      >
                        <summary class="article-expander__title">How SkillShow automates youth sports video processing using Amazon Transcribe</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/how-skillshow-automates-youth-sports-video-processing-using-amazon-transcribe/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/24/skillshow.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>SkillShow, a leader in youth sports video production, films over 300 events yearly in the youth sports industry, creating content for over 20,000 young athletes annually. This post describes how SkillShow used Amazon Transcribe and other Amazon Web Services (AWS) machine learning (ML) services to automate their video processing workflow, reducing editing time and costs while scaling their operations.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="66e62c5bbdf81de8ce0169f57480bd7e8b7e0f26"
                        open
                      >
                        <summary class="article-expander__title">NewDay builds A Generative AI based Customer service Agent Assist with over 90% accuracy</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/newday-builds-a-generative-ai-based-customer-service-agent-assist-with-over-90-accuracy/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/24/newday.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This post is co-written with Sergio Zavota and Amy Perring from NewDay. NewDay has a clear and defining purpose: to help people move forward with credit. NewDay provides around 4 million customers access to credit responsibly and delivers exceptional customer experiences, powered by their in-house technology system. NewDay’s contact center handles 2.5 million calls annually, […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;95
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2025-06-23 datetime="2025-06-23T17:38:55.000Z">2025-06-23</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2025-06-23 datetime="2025-06-23T17:38:55.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Artificial Intelligence</button>
                  <a class="source-heading__link" href="https://aws.amazon.com/blogs/machine-learning/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="89f277f6c14655dced1b55ebe2ca2f37dcb755cb"
                        open
                      >
                        <summary class="article-expander__title">No-code data preparation for time series forecasting using Amazon SageMaker Canvas</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/no-code-data-preparation-for-time-series-forecasting-using-amazon-sagemaker-canvas/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/06/chatfordataprep-1166x630.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Amazon SageMaker Canvas offers no-code solutions that simplify data wrangling, making time series forecasting accessible to all users regardless of their technical background. In this post, we explore how SageMaker Canvas and SageMaker Data Wrangler provide no-code data preparation techniques that empower users of all backgrounds to prepare data and build time series forecasting models in a single interface with confidence.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;92
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="7a1bd2389bffaf30cf8b77418cbb7d16bce40a61"
                        open
                      >
                        <summary class="article-expander__title">Build an agentic multimodal AI assistant with Amazon Nova and Amazon Bedrock Data Automation</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://aws.amazon.com/blogs/machine-learning/build-an-agentic-multimodal-ai-assistant-with-amazon-nova-and-amazon-bedrock-data-automation/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/17/image-1-963x630.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In this post, we demonstrate how agentic workflow patterns such as Retrieval Augmented Generation (RAG), multi-tool orchestration, and conditional routing with LangGraph enable end-to-end solutions that artificial intelligence and machine learning (AI/ML) developers and enterprise architects can adopt and extend. We walk through an example of a financial management AI assistant that can provide quantitative research and grounded financial advice by analyzing both the earnings call (audio) and the presentation slides (images), along with relevant financial data feeds.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;98
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >SRE WEEKLY</button>
                  <a class="source-heading__link" href="https://sreweekly.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://sreweekly.com/?p&#x3D;1656"
                        open
                      >
                        <summary class="article-expander__title">SRE Weekly Issue #482</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://sreweekly.com/sre-weekly-issue-482/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>View on sreweekly.com A message from our sponsor, PagerDuty: Incidents move fast. But you’ll never get left behind with PagerDuty’s GenAI incident response assistant, available in all paid plans. Get instant business impact analysis, troubleshooting steps, and auto-drafted status updates—directly in Slack. Stop context-switching, start resolving faster. https://fnf.dev/4dZ5V36 Service Disruption on multiple Salesforce services on […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;4
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>

    <footer>
      <a class="footer-link" href="https://github.com/liuning0820/rss-reader/actions/runs/16425028406">
        <time id="build-timestamp" datetime="2025-07-21T18:27:53.788Z">2025-07-21T18:27:53.788Z</time>
      </a>
      <a class="footer-link" href="https://github.com/osmoscraft/osmosfeed">osmosfeed 1.15.1</a>
    </footer>
    <script src="index.js?v1.14.4"></script>
    <!-- %before-body-end.html% -->
  </body>

</html>